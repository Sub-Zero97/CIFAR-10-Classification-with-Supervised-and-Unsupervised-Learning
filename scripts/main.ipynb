{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "main.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "lw-S4PgTA7kA"
      },
      "source": [
        "# Step 1: Import Libraries\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import keras\n",
        "from keras import layers\n",
        "from sklearn import preprocessing\n",
        "from sklearn.metrics import confusion_matrix,accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.cluster import KMeans\n",
        "from scipy.optimize import linear_sum_assignment as linear_assignment\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0magr8K4-re"
      },
      "source": [
        "### SUPERVISED LEARNING APPROACH (SLA) ###"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HVRu0lJq5VW3"
      },
      "source": [
        "# Step 2: Data Loading:\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ryfUq7F4AEK"
      },
      "source": [
        "# Defining required methods\n",
        "\n",
        "def minmax(x):\n",
        "    x_scaled=[]\n",
        "    for i in range(len(x)):\n",
        "        x_scaled.append(x[i].flatten())\n",
        "    scaler = preprocessing.MinMaxScaler()\n",
        "    x_scaled = scaler.fit_transform(x_scaled)\n",
        "    return x_scaled\n",
        "\n",
        "def sigmoid(z):\n",
        "    return 1 / (1 + np.exp(-z)) \n",
        "\n",
        "def softmax(z):\n",
        "    z=z.T\n",
        "    for i in range(z.shape[0]):\n",
        "        z[i] = np.exp(z[i])\n",
        "        sum_ = sum(z[i])\n",
        "        z[i] = z[i]/sum_\n",
        "    return z.T\n",
        "\n",
        "def calc_accuracy(p,y):\n",
        "    p=p.T\n",
        "    y=y.T\n",
        "    p_class=[]\n",
        "    y_class=[]\n",
        "    for i in range(p.shape[0]):\n",
        "        p_class.append(np.argmax(p[i]))\n",
        "        y_class.append(np.argmax(y[i])) \n",
        "    return accuracy_score(y_class, p_class)*100\n",
        "\n",
        "def calculate_loss(y,p):\n",
        "    value = []\n",
        "    y=y.T\n",
        "    p=p.T\n",
        "    for i in range(y.shape[0]):\n",
        "        val = np.multiply(y[i],np.log(p[i]))\n",
        "        value.append(sum(val))\n",
        "    CCE = -(1 / y.shape[0]) *np.sum(value)\n",
        "    return CCE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPpRr7d_4A3d"
      },
      "source": [
        "# Step 3: Scaling Image Pixel Values \n",
        "\n",
        "x_train =minmax(x_train)\n",
        "x_test  =minmax(x_test)\n",
        "\n",
        "x_train =np.array(x_train).reshape(50000,32,32,3)\n",
        "x_test  =np.array(x_test).reshape(10000,32,32,3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OMqrFoIE4BBq"
      },
      "source": [
        "# Step 4: One Hot Encoding of target variable \n",
        "\n",
        "Train_y=[]\n",
        "\n",
        "for i in range(y_train.shape[0]):\n",
        "    val = [0 for j in range(10)]\n",
        "    val[int(y_train[i])]=1\n",
        "    Train_y.append(val)\n",
        "    \n",
        "y_train=np.asarray(Train_y)\n",
        "\n",
        "Test_y=[]\n",
        "\n",
        "for i in range(y_test.shape[0]):\n",
        "    val = [0 for j in range(10)]\n",
        "    val[int(y_test[i])]=1\n",
        "    Test_y.append(val)\n",
        "    \n",
        "y_test=np.asarray(Test_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1A9Bqlx24BGE"
      },
      "source": [
        "# Step 5: Initialization of Variables \n",
        "  \n",
        "epochs=700\n",
        "\n",
        "learning_rate = 0.1\n",
        "\n",
        "m=x_train.shape[0]\n",
        "\n",
        "W1 = np.random.randn(300,3072)*0.1\n",
        "b1 = np.zeros((300,1))\n",
        "W2 = np.random.randn(10,300)*0.1\n",
        "b2 = np.zeros((10,1))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYklE38s4BJr"
      },
      "source": [
        "# Flattening the features: (32,32,3) --> (3072)\n",
        "Train_x=[]\n",
        "for i in range(x_train.shape[0]):\n",
        "    Train_x.append(x_train[i].flatten())\n",
        "    \n",
        "x_train = np.asarray(Train_x)\n",
        "\n",
        "Test_x=[]\n",
        "for i in range(x_test.shape[0]):\n",
        "    Test_x.append(x_test[i].flatten())\n",
        "    \n",
        "x_test = np.asarray(Test_x)\n",
        "\n",
        "# Initialising loss_track and accuracy_track variables\n",
        "losstrack_train = [] \n",
        "losstrack_test = [] \n",
        "\n",
        "train_accuracy = [] \n",
        "test_accuracy = [] \n",
        "\n",
        "x_train=x_train.T\n",
        "y_train=y_train.T\n",
        "\n",
        "x_test=x_test.T\n",
        "y_test=y_test.T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "at4CwrdB4l_0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b71fdf53-e9c7-4ad5-9510-f566ca185891"
      },
      "source": [
        "#Step 6: Training a Neural Network with 1 hidden layer using Gradient Descent Algorithm\n",
        "\n",
        "for epoch in range(epochs):\n",
        "\n",
        "    # Step 6.1: Use genesis equation y_pred = SM(W2.(W1X +b1)+b2)       \n",
        "    # train\n",
        "    Z1 = np.dot(W1,x_train) + b1\n",
        "    A1 = sigmoid(Z1)\n",
        "    Z2 = np.dot(W2,A1) + b2\n",
        "    A2 = softmax(Z2)\n",
        "    # test\n",
        "    Z11 = np.dot(W1,x_test) + b1\n",
        "    A11 = sigmoid(Z11)\n",
        "    Z22 = np.dot(W2,A11) + b2\n",
        "    A22 = softmax(Z22)\n",
        "\n",
        "    # Step 6.2: Find Categorical Cross Entropy Loss (L) for predicted value A2 and truth value y\n",
        "    # train\n",
        "    CCE_train = calculate_loss(y_train,A2)\n",
        "    losstrack_train.append(np.squeeze(CCE_train))\n",
        "    #test\n",
        "    CCE_test = calculate_loss(y_test,A22)\n",
        "    losstrack_test.append(np.squeeze(CCE_test))\n",
        "\n",
        "    # Step 6.3: Find dW1, db1, dW2, db2\n",
        "    dZ2 = A2 - y_train\n",
        "    dW2 = 1 / m * (np.dot(dZ2,A1.T))\n",
        "    db2 = 1 / m * (np.sum(dZ2,axis = 1,keepdims = True))\n",
        "    dZ1 = np.dot(W2.T,dZ2) * (A1*(1-A1))\n",
        "    dW1 = 1 / m * (np.dot(dZ1,x_train.T))\n",
        "    db1 = 1 / m * (np.sum(dZ1,axis = 1,keepdims = True))\n",
        "        \n",
        "    # Step 6.4: Update W1, W2, b1, b2 using learning rate\n",
        "    W1 = W1 - learning_rate * dW1\n",
        "    b1 = b1 - learning_rate * db1\n",
        "    W2 = W2 - learning_rate * dW2\n",
        "    b2 = b2 - learning_rate * db2  \n",
        "\n",
        "    \n",
        "    # Step 6.5: Find Train and Test Accuracy\n",
        "    train_acc = calc_accuracy(A2,y_train)\n",
        "    test_acc  = calc_accuracy(A22,y_test)\n",
        "    \n",
        "    train_accuracy.append(np.squeeze(train_acc))\n",
        "    test_accuracy.append(np.squeeze(test_acc))\n",
        "\n",
        "\n",
        "    if epoch%1==0: \n",
        "        print(\"epoch : \",epoch+1,\"/\",epochs)\n",
        "        print(\"train_acc = \" + str(train_acc) )\n",
        "        print(\"test_acc = \" + str(test_acc) )\n",
        "        print(\"loss = \" + str(CCE_train) )\n",
        "        print(\"\")\n",
        "        # print(\"test_loss = \" + str(CCE_test) )\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch :  1 / 700\n",
            "train_acc = 9.914000000000001\n",
            "test_acc = 10.02\n",
            "loss = 2.8722237261031647\n",
            "\n",
            "epoch :  2 / 700\n",
            "train_acc = 9.42\n",
            "test_acc = 9.120000000000001\n",
            "loss = 2.415905767455912\n",
            "\n",
            "epoch :  3 / 700\n",
            "train_acc = 14.216000000000001\n",
            "test_acc = 14.23\n",
            "loss = 2.317602999122398\n",
            "\n",
            "epoch :  4 / 700\n",
            "train_acc = 13.533999999999999\n",
            "test_acc = 13.61\n",
            "loss = 2.3004045926974666\n",
            "\n",
            "epoch :  5 / 700\n",
            "train_acc = 15.366\n",
            "test_acc = 15.620000000000001\n",
            "loss = 2.2882767454083726\n",
            "\n",
            "epoch :  6 / 700\n",
            "train_acc = 16.04\n",
            "test_acc = 16.220000000000002\n",
            "loss = 2.2772136297998693\n",
            "\n",
            "epoch :  7 / 700\n",
            "train_acc = 16.832\n",
            "test_acc = 17.330000000000002\n",
            "loss = 2.2667124905857197\n",
            "\n",
            "epoch :  8 / 700\n",
            "train_acc = 17.477999999999998\n",
            "test_acc = 17.84\n",
            "loss = 2.2566719409678413\n",
            "\n",
            "epoch :  9 / 700\n",
            "train_acc = 18.09\n",
            "test_acc = 18.529999999999998\n",
            "loss = 2.2470530985744617\n",
            "\n",
            "epoch :  10 / 700\n",
            "train_acc = 18.72\n",
            "test_acc = 18.84\n",
            "loss = 2.2378309861922143\n",
            "\n",
            "epoch :  11 / 700\n",
            "train_acc = 19.31\n",
            "test_acc = 19.39\n",
            "loss = 2.2289840354389585\n",
            "\n",
            "epoch :  12 / 700\n",
            "train_acc = 19.778000000000002\n",
            "test_acc = 19.78\n",
            "loss = 2.220492837733529\n",
            "\n",
            "epoch :  13 / 700\n",
            "train_acc = 20.25\n",
            "test_acc = 20.27\n",
            "loss = 2.2123389817207753\n",
            "\n",
            "epoch :  14 / 700\n",
            "train_acc = 20.682000000000002\n",
            "test_acc = 20.64\n",
            "loss = 2.2045052077332783\n",
            "\n",
            "epoch :  15 / 700\n",
            "train_acc = 21.084\n",
            "test_acc = 21.029999999999998\n",
            "loss = 2.1969751455701294\n",
            "\n",
            "epoch :  16 / 700\n",
            "train_acc = 21.496000000000002\n",
            "test_acc = 21.42\n",
            "loss = 2.189733484962391\n",
            "\n",
            "epoch :  17 / 700\n",
            "train_acc = 21.854000000000003\n",
            "test_acc = 21.75\n",
            "loss = 2.182765883351699\n",
            "\n",
            "epoch :  18 / 700\n",
            "train_acc = 22.220000000000002\n",
            "test_acc = 22.25\n",
            "loss = 2.176058997336405\n",
            "\n",
            "epoch :  19 / 700\n",
            "train_acc = 22.592000000000002\n",
            "test_acc = 22.5\n",
            "loss = 2.169600340958356\n",
            "\n",
            "epoch :  20 / 700\n",
            "train_acc = 22.898\n",
            "test_acc = 22.919999999999998\n",
            "loss = 2.1633781643968497\n",
            "\n",
            "epoch :  21 / 700\n",
            "train_acc = 23.128\n",
            "test_acc = 23.11\n",
            "loss = 2.1573812540233845\n",
            "\n",
            "epoch :  22 / 700\n",
            "train_acc = 23.41\n",
            "test_acc = 23.400000000000002\n",
            "loss = 2.1515987709409887\n",
            "\n",
            "epoch :  23 / 700\n",
            "train_acc = 23.666\n",
            "test_acc = 23.69\n",
            "loss = 2.1460201100273677\n",
            "\n",
            "epoch :  24 / 700\n",
            "train_acc = 23.9\n",
            "test_acc = 23.919999999999998\n",
            "loss = 2.1406348360951193\n",
            "\n",
            "epoch :  25 / 700\n",
            "train_acc = 24.156\n",
            "test_acc = 24.22\n",
            "loss = 2.1354326800723857\n",
            "\n",
            "epoch :  26 / 700\n",
            "train_acc = 24.343999999999998\n",
            "test_acc = 24.490000000000002\n",
            "loss = 2.130403595690852\n",
            "\n",
            "epoch :  27 / 700\n",
            "train_acc = 24.562\n",
            "test_acc = 24.66\n",
            "loss = 2.1255378450742306\n",
            "\n",
            "epoch :  28 / 700\n",
            "train_acc = 24.754\n",
            "test_acc = 25.03\n",
            "loss = 2.1208260932382905\n",
            "\n",
            "epoch :  29 / 700\n",
            "train_acc = 24.984\n",
            "test_acc = 25.240000000000002\n",
            "loss = 2.116259488657089\n",
            "\n",
            "epoch :  30 / 700\n",
            "train_acc = 25.191999999999997\n",
            "test_acc = 25.46\n",
            "loss = 2.111829720338453\n",
            "\n",
            "epoch :  31 / 700\n",
            "train_acc = 25.336\n",
            "test_acc = 25.590000000000003\n",
            "loss = 2.1075290469939265\n",
            "\n",
            "epoch :  32 / 700\n",
            "train_acc = 25.556\n",
            "test_acc = 25.75\n",
            "loss = 2.103350301441477\n",
            "\n",
            "epoch :  33 / 700\n",
            "train_acc = 25.718000000000004\n",
            "test_acc = 25.89\n",
            "loss = 2.099286875277587\n",
            "\n",
            "epoch :  34 / 700\n",
            "train_acc = 25.894000000000002\n",
            "test_acc = 26.13\n",
            "loss = 2.0953326902611984\n",
            "\n",
            "epoch :  35 / 700\n",
            "train_acc = 26.046000000000003\n",
            "test_acc = 26.279999999999998\n",
            "loss = 2.0914821617931802\n",
            "\n",
            "epoch :  36 / 700\n",
            "train_acc = 26.201999999999998\n",
            "test_acc = 26.39\n",
            "loss = 2.0877301589027333\n",
            "\n",
            "epoch :  37 / 700\n",
            "train_acc = 26.351999999999997\n",
            "test_acc = 26.44\n",
            "loss = 2.084071963673487\n",
            "\n",
            "epoch :  38 / 700\n",
            "train_acc = 26.497999999999998\n",
            "test_acc = 26.55\n",
            "loss = 2.080503232036961\n",
            "\n",
            "epoch :  39 / 700\n",
            "train_acc = 26.619999999999997\n",
            "test_acc = 26.669999999999998\n",
            "loss = 2.077019956956181\n",
            "\n",
            "epoch :  40 / 700\n",
            "train_acc = 26.772000000000002\n",
            "test_acc = 26.85\n",
            "loss = 2.07361843450577\n",
            "\n",
            "epoch :  41 / 700\n",
            "train_acc = 26.922\n",
            "test_acc = 27.01\n",
            "loss = 2.070295232973738\n",
            "\n",
            "epoch :  42 / 700\n",
            "train_acc = 27.052\n",
            "test_acc = 27.250000000000004\n",
            "loss = 2.067047164934266\n",
            "\n",
            "epoch :  43 / 700\n",
            "train_acc = 27.192\n",
            "test_acc = 27.42\n",
            "loss = 2.0638712621286768\n",
            "\n",
            "epoch :  44 / 700\n",
            "train_acc = 27.314\n",
            "test_acc = 27.54\n",
            "loss = 2.0607647529622755\n",
            "\n",
            "epoch :  45 / 700\n",
            "train_acc = 27.46\n",
            "test_acc = 27.71\n",
            "loss = 2.0577250424109987\n",
            "\n",
            "epoch :  46 / 700\n",
            "train_acc = 27.61\n",
            "test_acc = 27.72\n",
            "loss = 2.0547496941434202\n",
            "\n",
            "epoch :  47 / 700\n",
            "train_acc = 27.724\n",
            "test_acc = 27.82\n",
            "loss = 2.0518364146728643\n",
            "\n",
            "epoch :  48 / 700\n",
            "train_acc = 27.832\n",
            "test_acc = 27.98\n",
            "loss = 2.0489830393683706\n",
            "\n",
            "epoch :  49 / 700\n",
            "train_acc = 27.932000000000002\n",
            "test_acc = 28.09\n",
            "loss = 2.0461875201619173\n",
            "\n",
            "epoch :  50 / 700\n",
            "train_acc = 28.064\n",
            "test_acc = 28.27\n",
            "loss = 2.0434479147977593\n",
            "\n",
            "epoch :  51 / 700\n",
            "train_acc = 28.174\n",
            "test_acc = 28.360000000000003\n",
            "loss = 2.0407623774749646\n",
            "\n",
            "epoch :  52 / 700\n",
            "train_acc = 28.296\n",
            "test_acc = 28.51\n",
            "loss = 2.0381291507393753\n",
            "\n",
            "epoch :  53 / 700\n",
            "train_acc = 28.362\n",
            "test_acc = 28.63\n",
            "loss = 2.0355465584856516\n",
            "\n",
            "epoch :  54 / 700\n",
            "train_acc = 28.438000000000002\n",
            "test_acc = 28.749999999999996\n",
            "loss = 2.0330129999354276\n",
            "\n",
            "epoch :  55 / 700\n",
            "train_acc = 28.548000000000002\n",
            "test_acc = 28.84\n",
            "loss = 2.030526944463641\n",
            "\n",
            "epoch :  56 / 700\n",
            "train_acc = 28.64\n",
            "test_acc = 28.9\n",
            "loss = 2.0280869271525535\n",
            "\n",
            "epoch :  57 / 700\n",
            "train_acc = 28.727999999999998\n",
            "test_acc = 28.999999999999996\n",
            "loss = 2.025691544961322\n",
            "\n",
            "epoch :  58 / 700\n",
            "train_acc = 28.805999999999997\n",
            "test_acc = 29.099999999999998\n",
            "loss = 2.023339453408354\n",
            "\n",
            "epoch :  59 / 700\n",
            "train_acc = 28.910000000000004\n",
            "test_acc = 29.25\n",
            "loss = 2.0210293636735583\n",
            "\n",
            "epoch :  60 / 700\n",
            "train_acc = 28.982000000000003\n",
            "test_acc = 29.270000000000003\n",
            "loss = 2.0187600400377\n",
            "\n",
            "epoch :  61 / 700\n",
            "train_acc = 29.055999999999997\n",
            "test_acc = 29.38\n",
            "loss = 2.0165302975860584\n",
            "\n",
            "epoch :  62 / 700\n",
            "train_acc = 29.128\n",
            "test_acc = 29.43\n",
            "loss = 2.014339000113142\n",
            "\n",
            "epoch :  63 / 700\n",
            "train_acc = 29.214000000000002\n",
            "test_acc = 29.53\n",
            "loss = 2.0121850581742415\n",
            "\n",
            "epoch :  64 / 700\n",
            "train_acc = 29.28\n",
            "test_acc = 29.59\n",
            "loss = 2.0100674272379178\n",
            "\n",
            "epoch :  65 / 700\n",
            "train_acc = 29.322\n",
            "test_acc = 29.709999999999997\n",
            "loss = 2.0079851059012133\n",
            "\n",
            "epoch :  66 / 700\n",
            "train_acc = 29.418\n",
            "test_acc = 29.74\n",
            "loss = 2.005937134136493\n",
            "\n",
            "epoch :  67 / 700\n",
            "train_acc = 29.482000000000003\n",
            "test_acc = 29.86\n",
            "loss = 2.0039225915454644\n",
            "\n",
            "epoch :  68 / 700\n",
            "train_acc = 29.54\n",
            "test_acc = 30.0\n",
            "loss = 2.001940595602231\n",
            "\n",
            "epoch :  69 / 700\n",
            "train_acc = 29.626\n",
            "test_acc = 30.049999999999997\n",
            "loss = 1.9999902998733516\n",
            "\n",
            "epoch :  70 / 700\n",
            "train_acc = 29.671999999999997\n",
            "test_acc = 30.12\n",
            "loss = 1.9980708922087653\n",
            "\n",
            "epoch :  71 / 700\n",
            "train_acc = 29.748\n",
            "test_acc = 30.15\n",
            "loss = 1.9961815929031772\n",
            "\n",
            "epoch :  72 / 700\n",
            "train_acc = 29.84\n",
            "test_acc = 30.2\n",
            "loss = 1.9943216528330043\n",
            "\n",
            "epoch :  73 / 700\n",
            "train_acc = 29.909999999999997\n",
            "test_acc = 30.270000000000003\n",
            "loss = 1.9924903515790031\n",
            "\n",
            "epoch :  74 / 700\n",
            "train_acc = 29.994\n",
            "test_acc = 30.3\n",
            "loss = 1.9906869955492004\n",
            "\n",
            "epoch :  75 / 700\n",
            "train_acc = 30.064\n",
            "test_acc = 30.330000000000002\n",
            "loss = 1.9889109161203848\n",
            "\n",
            "epoch :  76 / 700\n",
            "train_acc = 30.128\n",
            "test_acc = 30.3\n",
            "loss = 1.987161467818999\n",
            "\n",
            "epoch :  77 / 700\n",
            "train_acc = 30.212\n",
            "test_acc = 30.34\n",
            "loss = 1.9854380265636866\n",
            "\n",
            "epoch :  78 / 700\n",
            "train_acc = 30.284\n",
            "test_acc = 30.349999999999998\n",
            "loss = 1.9837399879917614\n",
            "\n",
            "epoch :  79 / 700\n",
            "train_acc = 30.346\n",
            "test_acc = 30.459999999999997\n",
            "loss = 1.9820667658906197\n",
            "\n",
            "epoch :  80 / 700\n",
            "train_acc = 30.392000000000003\n",
            "test_acc = 30.53\n",
            "loss = 1.9804177907525142\n",
            "\n",
            "epoch :  81 / 700\n",
            "train_acc = 30.458000000000002\n",
            "test_acc = 30.680000000000003\n",
            "loss = 1.9787925084675109\n",
            "\n",
            "epoch :  82 / 700\n",
            "train_acc = 30.525999999999996\n",
            "test_acc = 30.769999999999996\n",
            "loss = 1.9771903791649779\n",
            "\n",
            "epoch :  83 / 700\n",
            "train_acc = 30.59\n",
            "test_acc = 30.89\n",
            "loss = 1.9756108762090472\n",
            "\n",
            "epoch :  84 / 700\n",
            "train_acc = 30.636000000000003\n",
            "test_acc = 30.919999999999998\n",
            "loss = 1.974053485348417\n",
            "\n",
            "epoch :  85 / 700\n",
            "train_acc = 30.724\n",
            "test_acc = 30.990000000000002\n",
            "loss = 1.9725177040160313\n",
            "\n",
            "epoch :  86 / 700\n",
            "train_acc = 30.788\n",
            "test_acc = 31.05\n",
            "loss = 1.9710030407698251\n",
            "\n",
            "epoch :  87 / 700\n",
            "train_acc = 30.858\n",
            "test_acc = 31.130000000000003\n",
            "loss = 1.9695090148621461\n",
            "\n",
            "epoch :  88 / 700\n",
            "train_acc = 30.872\n",
            "test_acc = 31.180000000000003\n",
            "loss = 1.9680351559227551\n",
            "\n",
            "epoch :  89 / 700\n",
            "train_acc = 30.928\n",
            "test_acc = 31.22\n",
            "loss = 1.9665810037385842\n",
            "\n",
            "epoch :  90 / 700\n",
            "train_acc = 30.98\n",
            "test_acc = 31.269999999999996\n",
            "loss = 1.9651461081126274\n",
            "\n",
            "epoch :  91 / 700\n",
            "train_acc = 31.048\n",
            "test_acc = 31.319999999999997\n",
            "loss = 1.9637300287844284\n",
            "\n",
            "epoch :  92 / 700\n",
            "train_acc = 31.092\n",
            "test_acc = 31.36\n",
            "loss = 1.9623323353954107\n",
            "\n",
            "epoch :  93 / 700\n",
            "train_acc = 31.14\n",
            "test_acc = 31.419999999999998\n",
            "loss = 1.9609526074837045\n",
            "\n",
            "epoch :  94 / 700\n",
            "train_acc = 31.203999999999997\n",
            "test_acc = 31.480000000000004\n",
            "loss = 1.9595904344948811\n",
            "\n",
            "epoch :  95 / 700\n",
            "train_acc = 31.236000000000004\n",
            "test_acc = 31.47\n",
            "loss = 1.9582454157970595\n",
            "\n",
            "epoch :  96 / 700\n",
            "train_acc = 31.284\n",
            "test_acc = 31.5\n",
            "loss = 1.9569171606909468\n",
            "\n",
            "epoch :  97 / 700\n",
            "train_acc = 31.324\n",
            "test_acc = 31.580000000000002\n",
            "loss = 1.9556052884074788\n",
            "\n",
            "epoch :  98 / 700\n",
            "train_acc = 31.391999999999996\n",
            "test_acc = 31.680000000000003\n",
            "loss = 1.9543094280876945\n",
            "\n",
            "epoch :  99 / 700\n",
            "train_acc = 31.444\n",
            "test_acc = 31.740000000000002\n",
            "loss = 1.953029218741258\n",
            "\n",
            "epoch :  100 / 700\n",
            "train_acc = 31.490000000000002\n",
            "test_acc = 31.81\n",
            "loss = 1.9517643091815826\n",
            "\n",
            "epoch :  101 / 700\n",
            "train_acc = 31.540000000000003\n",
            "test_acc = 31.86\n",
            "loss = 1.9505143579368203\n",
            "\n",
            "epoch :  102 / 700\n",
            "train_acc = 31.572\n",
            "test_acc = 31.929999999999996\n",
            "loss = 1.94927903313703\n",
            "\n",
            "epoch :  103 / 700\n",
            "train_acc = 31.602000000000004\n",
            "test_acc = 31.97\n",
            "loss = 1.9480580123786457\n",
            "\n",
            "epoch :  104 / 700\n",
            "train_acc = 31.652\n",
            "test_acc = 31.97\n",
            "loss = 1.946850982567965\n",
            "\n",
            "epoch :  105 / 700\n",
            "train_acc = 31.674000000000003\n",
            "test_acc = 32.0\n",
            "loss = 1.9456576397457996\n",
            "\n",
            "epoch :  106 / 700\n",
            "train_acc = 31.718000000000004\n",
            "test_acc = 31.990000000000002\n",
            "loss = 1.9444776888956559\n",
            "\n",
            "epoch :  107 / 700\n",
            "train_acc = 31.75\n",
            "test_acc = 32.05\n",
            "loss = 1.943310843737954\n",
            "\n",
            "epoch :  108 / 700\n",
            "train_acc = 31.832\n",
            "test_acc = 32.2\n",
            "loss = 1.942156826512796\n",
            "\n",
            "epoch :  109 / 700\n",
            "train_acc = 31.86\n",
            "test_acc = 32.26\n",
            "loss = 1.9410153677537219\n",
            "\n",
            "epoch :  110 / 700\n",
            "train_acc = 31.902\n",
            "test_acc = 32.36\n",
            "loss = 1.9398862060547875\n",
            "\n",
            "epoch :  111 / 700\n",
            "train_acc = 31.958\n",
            "test_acc = 32.35\n",
            "loss = 1.9387690878331103\n",
            "\n",
            "epoch :  112 / 700\n",
            "train_acc = 31.990000000000002\n",
            "test_acc = 32.41\n",
            "loss = 1.9376637670888561\n",
            "\n",
            "epoch :  113 / 700\n",
            "train_acc = 32.052\n",
            "test_acc = 32.42\n",
            "loss = 1.9365700051644217\n",
            "\n",
            "epoch :  114 / 700\n",
            "train_acc = 32.1\n",
            "test_acc = 32.5\n",
            "loss = 1.9354875705043804\n",
            "\n",
            "epoch :  115 / 700\n",
            "train_acc = 32.138\n",
            "test_acc = 32.5\n",
            "loss = 1.9344162384175232\n",
            "\n",
            "epoch :  116 / 700\n",
            "train_acc = 32.182\n",
            "test_acc = 32.48\n",
            "loss = 1.9333557908421541\n",
            "\n",
            "epoch :  117 / 700\n",
            "train_acc = 32.234\n",
            "test_acc = 32.53\n",
            "loss = 1.9323060161155987\n",
            "\n",
            "epoch :  118 / 700\n",
            "train_acc = 32.269999999999996\n",
            "test_acc = 32.57\n",
            "loss = 1.9312667087487085\n",
            "\n",
            "epoch :  119 / 700\n",
            "train_acc = 32.322\n",
            "test_acc = 32.59\n",
            "loss = 1.9302376692059955\n",
            "\n",
            "epoch :  120 / 700\n",
            "train_acc = 32.374\n",
            "test_acc = 32.66\n",
            "loss = 1.9292187036918627\n",
            "\n",
            "epoch :  121 / 700\n",
            "train_acc = 32.444\n",
            "test_acc = 32.73\n",
            "loss = 1.928209623943302\n",
            "\n",
            "epoch :  122 / 700\n",
            "train_acc = 32.466\n",
            "test_acc = 32.769999999999996\n",
            "loss = 1.927210247029277\n",
            "\n",
            "epoch :  123 / 700\n",
            "train_acc = 32.496\n",
            "test_acc = 32.800000000000004\n",
            "loss = 1.9262203951569368\n",
            "\n",
            "epoch :  124 / 700\n",
            "train_acc = 32.532\n",
            "test_acc = 32.87\n",
            "loss = 1.9252398954847105\n",
            "\n",
            "epoch :  125 / 700\n",
            "train_acc = 32.554\n",
            "test_acc = 32.92\n",
            "loss = 1.9242685799422532\n",
            "\n",
            "epoch :  126 / 700\n",
            "train_acc = 32.586\n",
            "test_acc = 32.99\n",
            "loss = 1.9233062850571727\n",
            "\n",
            "epoch :  127 / 700\n",
            "train_acc = 32.61\n",
            "test_acc = 33.01\n",
            "loss = 1.9223528517883883\n",
            "\n",
            "epoch :  128 / 700\n",
            "train_acc = 32.656\n",
            "test_acc = 33.050000000000004\n",
            "loss = 1.9214081253659643\n",
            "\n",
            "epoch :  129 / 700\n",
            "train_acc = 32.698\n",
            "test_acc = 33.09\n",
            "loss = 1.9204719551372125\n",
            "\n",
            "epoch :  130 / 700\n",
            "train_acc = 32.738\n",
            "test_acc = 33.129999999999995\n",
            "loss = 1.9195441944188407\n",
            "\n",
            "epoch :  131 / 700\n",
            "train_acc = 32.748\n",
            "test_acc = 33.2\n",
            "loss = 1.9186247003549184\n",
            "\n",
            "epoch :  132 / 700\n",
            "train_acc = 32.794000000000004\n",
            "test_acc = 33.269999999999996\n",
            "loss = 1.9177133337804153\n",
            "\n",
            "epoch :  133 / 700\n",
            "train_acc = 32.844\n",
            "test_acc = 33.33\n",
            "loss = 1.9168099590900722\n",
            "\n",
            "epoch :  134 / 700\n",
            "train_acc = 32.896\n",
            "test_acc = 33.39\n",
            "loss = 1.915914444112368\n",
            "\n",
            "epoch :  135 / 700\n",
            "train_acc = 32.936\n",
            "test_acc = 33.48\n",
            "loss = 1.9150266599883516\n",
            "\n",
            "epoch :  136 / 700\n",
            "train_acc = 32.976\n",
            "test_acc = 33.53\n",
            "loss = 1.9141464810551148\n",
            "\n",
            "epoch :  137 / 700\n",
            "train_acc = 33.006\n",
            "test_acc = 33.57\n",
            "loss = 1.9132737847337082\n",
            "\n",
            "epoch :  138 / 700\n",
            "train_acc = 33.024\n",
            "test_acc = 33.58\n",
            "loss = 1.912408451421297\n",
            "\n",
            "epoch :  139 / 700\n",
            "train_acc = 33.056000000000004\n",
            "test_acc = 33.6\n",
            "loss = 1.9115503643873812\n",
            "\n",
            "epoch :  140 / 700\n",
            "train_acc = 33.092\n",
            "test_acc = 33.650000000000006\n",
            "loss = 1.9106994096739227\n",
            "\n",
            "epoch :  141 / 700\n",
            "train_acc = 33.126\n",
            "test_acc = 33.75\n",
            "loss = 1.9098554759992146\n",
            "\n",
            "epoch :  142 / 700\n",
            "train_acc = 33.138\n",
            "test_acc = 33.72\n",
            "loss = 1.9090184546653761\n",
            "\n",
            "epoch :  143 / 700\n",
            "train_acc = 33.176\n",
            "test_acc = 33.73\n",
            "loss = 1.9081882394693348\n",
            "\n",
            "epoch :  144 / 700\n",
            "train_acc = 33.216\n",
            "test_acc = 33.739999999999995\n",
            "loss = 1.907364726617191\n",
            "\n",
            "epoch :  145 / 700\n",
            "train_acc = 33.228\n",
            "test_acc = 33.76\n",
            "loss = 1.9065478146418677\n",
            "\n",
            "epoch :  146 / 700\n",
            "train_acc = 33.26\n",
            "test_acc = 33.79\n",
            "loss = 1.905737404323943\n",
            "\n",
            "epoch :  147 / 700\n",
            "train_acc = 33.284000000000006\n",
            "test_acc = 33.81\n",
            "loss = 1.9049333986155839\n",
            "\n",
            "epoch :  148 / 700\n",
            "train_acc = 33.314\n",
            "test_acc = 33.839999999999996\n",
            "loss = 1.9041357025675072\n",
            "\n",
            "epoch :  149 / 700\n",
            "train_acc = 33.342\n",
            "test_acc = 33.879999999999995\n",
            "loss = 1.9033442232588755\n",
            "\n",
            "epoch :  150 / 700\n",
            "train_acc = 33.388\n",
            "test_acc = 33.910000000000004\n",
            "loss = 1.902558869730071\n",
            "\n",
            "epoch :  151 / 700\n",
            "train_acc = 33.44\n",
            "test_acc = 33.910000000000004\n",
            "loss = 1.9017795529182588\n",
            "\n",
            "epoch :  152 / 700\n",
            "train_acc = 33.478\n",
            "test_acc = 33.95\n",
            "loss = 1.901006185595675\n",
            "\n",
            "epoch :  153 / 700\n",
            "train_acc = 33.513999999999996\n",
            "test_acc = 33.96\n",
            "loss = 1.9002386823105668\n",
            "\n",
            "epoch :  154 / 700\n",
            "train_acc = 33.528000000000006\n",
            "test_acc = 33.98\n",
            "loss = 1.8994769593306997\n",
            "\n",
            "epoch :  155 / 700\n",
            "train_acc = 33.552\n",
            "test_acc = 34.02\n",
            "loss = 1.8987209345893665\n",
            "\n",
            "epoch :  156 / 700\n",
            "train_acc = 33.592\n",
            "test_acc = 34.14\n",
            "loss = 1.8979705276338124\n",
            "\n",
            "epoch :  157 / 700\n",
            "train_acc = 33.62\n",
            "test_acc = 34.2\n",
            "loss = 1.8972256595759953\n",
            "\n",
            "epoch :  158 / 700\n",
            "train_acc = 33.644\n",
            "test_acc = 34.23\n",
            "loss = 1.8964862530456017\n",
            "\n",
            "epoch :  159 / 700\n",
            "train_acc = 33.668\n",
            "test_acc = 34.239999999999995\n",
            "loss = 1.8957522321452231\n",
            "\n",
            "epoch :  160 / 700\n",
            "train_acc = 33.71\n",
            "test_acc = 34.29\n",
            "loss = 1.8950235224076273\n",
            "\n",
            "epoch :  161 / 700\n",
            "train_acc = 33.736\n",
            "test_acc = 34.32\n",
            "loss = 1.8943000507550072\n",
            "\n",
            "epoch :  162 / 700\n",
            "train_acc = 33.77\n",
            "test_acc = 34.32\n",
            "loss = 1.8935817454601485\n",
            "\n",
            "epoch :  163 / 700\n",
            "train_acc = 33.804\n",
            "test_acc = 34.37\n",
            "loss = 1.8928685361094064\n",
            "\n",
            "epoch :  164 / 700\n",
            "train_acc = 33.85\n",
            "test_acc = 34.38\n",
            "loss = 1.892160353567415\n",
            "\n",
            "epoch :  165 / 700\n",
            "train_acc = 33.896\n",
            "test_acc = 34.410000000000004\n",
            "loss = 1.8914571299434415\n",
            "\n",
            "epoch :  166 / 700\n",
            "train_acc = 33.934\n",
            "test_acc = 34.410000000000004\n",
            "loss = 1.8907587985592953\n",
            "\n",
            "epoch :  167 / 700\n",
            "train_acc = 33.967999999999996\n",
            "test_acc = 34.44\n",
            "loss = 1.8900652939187201\n",
            "\n",
            "epoch :  168 / 700\n",
            "train_acc = 33.98\n",
            "test_acc = 34.47\n",
            "loss = 1.889376551678176\n",
            "\n",
            "epoch :  169 / 700\n",
            "train_acc = 34.0\n",
            "test_acc = 34.47\n",
            "loss = 1.8886925086189512\n",
            "\n",
            "epoch :  170 / 700\n",
            "train_acc = 34.03\n",
            "test_acc = 34.489999999999995\n",
            "loss = 1.888013102620519\n",
            "\n",
            "epoch :  171 / 700\n",
            "train_acc = 34.06\n",
            "test_acc = 34.52\n",
            "loss = 1.887338272635075\n",
            "\n",
            "epoch :  172 / 700\n",
            "train_acc = 34.11\n",
            "test_acc = 34.56\n",
            "loss = 1.886667958663199\n",
            "\n",
            "epoch :  173 / 700\n",
            "train_acc = 34.148\n",
            "test_acc = 34.58\n",
            "loss = 1.8860021017305695\n",
            "\n",
            "epoch :  174 / 700\n",
            "train_acc = 34.168\n",
            "test_acc = 34.67\n",
            "loss = 1.8853406438656855\n",
            "\n",
            "epoch :  175 / 700\n",
            "train_acc = 34.182\n",
            "test_acc = 34.68\n",
            "loss = 1.8846835280785426\n",
            "\n",
            "epoch :  176 / 700\n",
            "train_acc = 34.25\n",
            "test_acc = 34.699999999999996\n",
            "loss = 1.884030698340222\n",
            "\n",
            "epoch :  177 / 700\n",
            "train_acc = 34.29\n",
            "test_acc = 34.72\n",
            "loss = 1.8833820995633426\n",
            "\n",
            "epoch :  178 / 700\n",
            "train_acc = 34.306\n",
            "test_acc = 34.74\n",
            "loss = 1.8827376775833526\n",
            "\n",
            "epoch :  179 / 700\n",
            "train_acc = 34.314\n",
            "test_acc = 34.79\n",
            "loss = 1.8820973791406197\n",
            "\n",
            "epoch :  180 / 700\n",
            "train_acc = 34.344\n",
            "test_acc = 34.79\n",
            "loss = 1.8814611518632944\n",
            "\n",
            "epoch :  181 / 700\n",
            "train_acc = 34.342\n",
            "test_acc = 34.8\n",
            "loss = 1.8808289442509227\n",
            "\n",
            "epoch :  182 / 700\n",
            "train_acc = 34.367999999999995\n",
            "test_acc = 34.83\n",
            "loss = 1.8802007056587895\n",
            "\n",
            "epoch :  183 / 700\n",
            "train_acc = 34.386\n",
            "test_acc = 34.839999999999996\n",
            "loss = 1.879576386282968\n",
            "\n",
            "epoch :  184 / 700\n",
            "train_acc = 34.388000000000005\n",
            "test_acc = 34.870000000000005\n",
            "loss = 1.8789559371460636\n",
            "\n",
            "epoch :  185 / 700\n",
            "train_acc = 34.426\n",
            "test_acc = 34.9\n",
            "loss = 1.8783393100836434\n",
            "\n",
            "epoch :  186 / 700\n",
            "train_acc = 34.446\n",
            "test_acc = 34.88\n",
            "loss = 1.8777264577313266\n",
            "\n",
            "epoch :  187 / 700\n",
            "train_acc = 34.452\n",
            "test_acc = 34.910000000000004\n",
            "loss = 1.877117333512537\n",
            "\n",
            "epoch :  188 / 700\n",
            "train_acc = 34.467999999999996\n",
            "test_acc = 34.96\n",
            "loss = 1.8765118916268995\n",
            "\n",
            "epoch :  189 / 700\n",
            "train_acc = 34.486\n",
            "test_acc = 35.010000000000005\n",
            "loss = 1.8759100870392753\n",
            "\n",
            "epoch :  190 / 700\n",
            "train_acc = 34.516000000000005\n",
            "test_acc = 34.99\n",
            "loss = 1.8753118754694207\n",
            "\n",
            "epoch :  191 / 700\n",
            "train_acc = 34.548\n",
            "test_acc = 35.05\n",
            "loss = 1.8747172133822596\n",
            "\n",
            "epoch :  192 / 700\n",
            "train_acc = 34.572\n",
            "test_acc = 35.06\n",
            "loss = 1.8741260579787586\n",
            "\n",
            "epoch :  193 / 700\n",
            "train_acc = 34.592\n",
            "test_acc = 35.08\n",
            "loss = 1.873538367187385\n",
            "\n",
            "epoch :  194 / 700\n",
            "train_acc = 34.605999999999995\n",
            "test_acc = 35.099999999999994\n",
            "loss = 1.8729540996561378\n",
            "\n",
            "epoch :  195 / 700\n",
            "train_acc = 34.62\n",
            "test_acc = 35.120000000000005\n",
            "loss = 1.8723732147451222\n",
            "\n",
            "epoch :  196 / 700\n",
            "train_acc = 34.636\n",
            "test_acc = 35.120000000000005\n",
            "loss = 1.8717956725196572\n",
            "\n",
            "epoch :  197 / 700\n",
            "train_acc = 34.660000000000004\n",
            "test_acc = 35.08\n",
            "loss = 1.8712214337438762\n",
            "\n",
            "epoch :  198 / 700\n",
            "train_acc = 34.67\n",
            "test_acc = 35.08\n",
            "loss = 1.8706504598748022\n",
            "\n",
            "epoch :  199 / 700\n",
            "train_acc = 34.71\n",
            "test_acc = 35.099999999999994\n",
            "loss = 1.8700827130568567\n",
            "\n",
            "epoch :  200 / 700\n",
            "train_acc = 34.716\n",
            "test_acc = 35.160000000000004\n",
            "loss = 1.869518156116766\n",
            "\n",
            "epoch :  201 / 700\n",
            "train_acc = 34.744\n",
            "test_acc = 35.18\n",
            "loss = 1.8689567525588215\n",
            "\n",
            "epoch :  202 / 700\n",
            "train_acc = 34.758\n",
            "test_acc = 35.23\n",
            "loss = 1.8683984665604496\n",
            "\n",
            "epoch :  203 / 700\n",
            "train_acc = 34.772\n",
            "test_acc = 35.35\n",
            "loss = 1.867843262968033\n",
            "\n",
            "epoch :  204 / 700\n",
            "train_acc = 34.782000000000004\n",
            "test_acc = 35.38\n",
            "loss = 1.8672911072929361\n",
            "\n",
            "epoch :  205 / 700\n",
            "train_acc = 34.784\n",
            "test_acc = 35.4\n",
            "loss = 1.866741965707664\n",
            "\n",
            "epoch :  206 / 700\n",
            "train_acc = 34.814\n",
            "test_acc = 35.43\n",
            "loss = 1.8661958050420995\n",
            "\n",
            "epoch :  207 / 700\n",
            "train_acc = 34.827999999999996\n",
            "test_acc = 35.43\n",
            "loss = 1.8656525927797443\n",
            "\n",
            "epoch :  208 / 700\n",
            "train_acc = 34.862\n",
            "test_acc = 35.43\n",
            "loss = 1.865112297053892\n",
            "\n",
            "epoch :  209 / 700\n",
            "train_acc = 34.904\n",
            "test_acc = 35.47\n",
            "loss = 1.8645748866436667\n",
            "\n",
            "epoch :  210 / 700\n",
            "train_acc = 34.922\n",
            "test_acc = 35.46\n",
            "loss = 1.8640403309698392\n",
            "\n",
            "epoch :  211 / 700\n",
            "train_acc = 34.961999999999996\n",
            "test_acc = 35.47\n",
            "loss = 1.8635086000903502\n",
            "\n",
            "epoch :  212 / 700\n",
            "train_acc = 34.967999999999996\n",
            "test_acc = 35.54\n",
            "loss = 1.8629796646954604\n",
            "\n",
            "epoch :  213 / 700\n",
            "train_acc = 35.002\n",
            "test_acc = 35.589999999999996\n",
            "loss = 1.8624534961024517\n",
            "\n",
            "epoch :  214 / 700\n",
            "train_acc = 35.016000000000005\n",
            "test_acc = 35.61\n",
            "loss = 1.8619300662497953\n",
            "\n",
            "epoch :  215 / 700\n",
            "train_acc = 35.042\n",
            "test_acc = 35.63\n",
            "loss = 1.861409347690721\n",
            "\n",
            "epoch :  216 / 700\n",
            "train_acc = 35.082\n",
            "test_acc = 35.66\n",
            "loss = 1.8608913135861085\n",
            "\n",
            "epoch :  217 / 700\n",
            "train_acc = 35.11\n",
            "test_acc = 35.68\n",
            "loss = 1.8603759376966431\n",
            "\n",
            "epoch :  218 / 700\n",
            "train_acc = 35.126000000000005\n",
            "test_acc = 35.74\n",
            "loss = 1.859863194374161\n",
            "\n",
            "epoch :  219 / 700\n",
            "train_acc = 35.148\n",
            "test_acc = 35.79\n",
            "loss = 1.8593530585521476\n",
            "\n",
            "epoch :  220 / 700\n",
            "train_acc = 35.18\n",
            "test_acc = 35.809999999999995\n",
            "loss = 1.8588455057353221\n",
            "\n",
            "epoch :  221 / 700\n",
            "train_acc = 35.19\n",
            "test_acc = 35.83\n",
            "loss = 1.858340511988289\n",
            "\n",
            "epoch :  222 / 700\n",
            "train_acc = 35.214\n",
            "test_acc = 35.83\n",
            "loss = 1.8578380539232124\n",
            "\n",
            "epoch :  223 / 700\n",
            "train_acc = 35.25\n",
            "test_acc = 35.88\n",
            "loss = 1.857338108686511\n",
            "\n",
            "epoch :  224 / 700\n",
            "train_acc = 35.256\n",
            "test_acc = 35.870000000000005\n",
            "loss = 1.8568406539445486\n",
            "\n",
            "epoch :  225 / 700\n",
            "train_acc = 35.288000000000004\n",
            "test_acc = 35.9\n",
            "loss = 1.8563456678683443\n",
            "\n",
            "epoch :  226 / 700\n",
            "train_acc = 35.312\n",
            "test_acc = 35.92\n",
            "loss = 1.855853129117308\n",
            "\n",
            "epoch :  227 / 700\n",
            "train_acc = 35.327999999999996\n",
            "test_acc = 35.96\n",
            "loss = 1.8553630168220347\n",
            "\n",
            "epoch :  228 / 700\n",
            "train_acc = 35.354\n",
            "test_acc = 35.99\n",
            "loss = 1.8548753105662044\n",
            "\n",
            "epoch :  229 / 700\n",
            "train_acc = 35.362\n",
            "test_acc = 36.02\n",
            "loss = 1.8543899903676329\n",
            "\n",
            "epoch :  230 / 700\n",
            "train_acc = 35.392\n",
            "test_acc = 35.980000000000004\n",
            "loss = 1.8539070366585553\n",
            "\n",
            "epoch :  231 / 700\n",
            "train_acc = 35.404\n",
            "test_acc = 35.980000000000004\n",
            "loss = 1.8534264302652075\n",
            "\n",
            "epoch :  232 / 700\n",
            "train_acc = 35.43\n",
            "test_acc = 36.0\n",
            "loss = 1.8529481523868048\n",
            "\n",
            "epoch :  233 / 700\n",
            "train_acc = 35.448\n",
            "test_acc = 36.01\n",
            "loss = 1.852472184574014\n",
            "\n",
            "epoch :  234 / 700\n",
            "train_acc = 35.472\n",
            "test_acc = 36.02\n",
            "loss = 1.851998508707032\n",
            "\n",
            "epoch :  235 / 700\n",
            "train_acc = 35.49\n",
            "test_acc = 36.04\n",
            "loss = 1.8515271069733779\n",
            "\n",
            "epoch :  236 / 700\n",
            "train_acc = 35.492000000000004\n",
            "test_acc = 36.04\n",
            "loss = 1.8510579618455345\n",
            "\n",
            "epoch :  237 / 700\n",
            "train_acc = 35.512\n",
            "test_acc = 36.08\n",
            "loss = 1.8505910560585603\n",
            "\n",
            "epoch :  238 / 700\n",
            "train_acc = 35.532000000000004\n",
            "test_acc = 36.120000000000005\n",
            "loss = 1.8501263725877979\n",
            "\n",
            "epoch :  239 / 700\n",
            "train_acc = 35.54\n",
            "test_acc = 36.18\n",
            "loss = 1.8496638946268236\n",
            "\n",
            "epoch :  240 / 700\n",
            "train_acc = 35.556\n",
            "test_acc = 36.22\n",
            "loss = 1.8492036055657615\n",
            "\n",
            "epoch :  241 / 700\n",
            "train_acc = 35.586\n",
            "test_acc = 36.199999999999996\n",
            "loss = 1.8487454889700927\n",
            "\n",
            "epoch :  242 / 700\n",
            "train_acc = 35.606\n",
            "test_acc = 36.230000000000004\n",
            "loss = 1.8482895285600913\n",
            "\n",
            "epoch :  243 / 700\n",
            "train_acc = 35.626000000000005\n",
            "test_acc = 36.24\n",
            "loss = 1.8478357081910028\n",
            "\n",
            "epoch :  244 / 700\n",
            "train_acc = 35.642\n",
            "test_acc = 36.28\n",
            "loss = 1.847384011834086\n",
            "\n",
            "epoch :  245 / 700\n",
            "train_acc = 35.674\n",
            "test_acc = 36.32\n",
            "loss = 1.846934423558616\n",
            "\n",
            "epoch :  246 / 700\n",
            "train_acc = 35.686\n",
            "test_acc = 36.32\n",
            "loss = 1.8464869275149556\n",
            "\n",
            "epoch :  247 / 700\n",
            "train_acc = 35.708\n",
            "test_acc = 36.32\n",
            "loss = 1.84604150791877\n",
            "\n",
            "epoch :  248 / 700\n",
            "train_acc = 35.730000000000004\n",
            "test_acc = 36.34\n",
            "loss = 1.8455981490364692\n",
            "\n",
            "epoch :  249 / 700\n",
            "train_acc = 35.736000000000004\n",
            "test_acc = 36.41\n",
            "loss = 1.8451568351719305\n",
            "\n",
            "epoch :  250 / 700\n",
            "train_acc = 35.754000000000005\n",
            "test_acc = 36.4\n",
            "loss = 1.8447175506545583\n",
            "\n",
            "epoch :  251 / 700\n",
            "train_acc = 35.758\n",
            "test_acc = 36.43\n",
            "loss = 1.8442802798287048\n",
            "\n",
            "epoch :  252 / 700\n",
            "train_acc = 35.774\n",
            "test_acc = 36.42\n",
            "loss = 1.84384500704449\n",
            "\n",
            "epoch :  253 / 700\n",
            "train_acc = 35.794\n",
            "test_acc = 36.41\n",
            "loss = 1.8434117166500097\n",
            "\n",
            "epoch :  254 / 700\n",
            "train_acc = 35.821999999999996\n",
            "test_acc = 36.44\n",
            "loss = 1.8429803929849404\n",
            "\n",
            "epoch :  255 / 700\n",
            "train_acc = 35.838\n",
            "test_acc = 36.449999999999996\n",
            "loss = 1.8425510203755173\n",
            "\n",
            "epoch :  256 / 700\n",
            "train_acc = 35.852000000000004\n",
            "test_acc = 36.46\n",
            "loss = 1.842123583130851\n",
            "\n",
            "epoch :  257 / 700\n",
            "train_acc = 35.868\n",
            "test_acc = 36.47\n",
            "loss = 1.8416980655405533\n",
            "\n",
            "epoch :  258 / 700\n",
            "train_acc = 35.888\n",
            "test_acc = 36.47\n",
            "loss = 1.8412744518736046\n",
            "\n",
            "epoch :  259 / 700\n",
            "train_acc = 35.912\n",
            "test_acc = 36.47\n",
            "loss = 1.8408527263784134\n",
            "\n",
            "epoch :  260 / 700\n",
            "train_acc = 35.936\n",
            "test_acc = 36.52\n",
            "loss = 1.8404328732839939\n",
            "\n",
            "epoch :  261 / 700\n",
            "train_acc = 35.936\n",
            "test_acc = 36.5\n",
            "loss = 1.8400148768021811\n",
            "\n",
            "epoch :  262 / 700\n",
            "train_acc = 35.968\n",
            "test_acc = 36.53\n",
            "loss = 1.839598721130811\n",
            "\n",
            "epoch :  263 / 700\n",
            "train_acc = 35.984\n",
            "test_acc = 36.57\n",
            "loss = 1.839184390457768\n",
            "\n",
            "epoch :  264 / 700\n",
            "train_acc = 36.004000000000005\n",
            "test_acc = 36.58\n",
            "loss = 1.8387718689658197\n",
            "\n",
            "epoch :  265 / 700\n",
            "train_acc = 36.016\n",
            "test_acc = 36.61\n",
            "loss = 1.8383611408381395\n",
            "\n",
            "epoch :  266 / 700\n",
            "train_acc = 36.042\n",
            "test_acc = 36.57\n",
            "loss = 1.8379521902644291\n",
            "\n",
            "epoch :  267 / 700\n",
            "train_acc = 36.052\n",
            "test_acc = 36.59\n",
            "loss = 1.8375450014475516\n",
            "\n",
            "epoch :  268 / 700\n",
            "train_acc = 36.07\n",
            "test_acc = 36.64\n",
            "loss = 1.8371395586105743\n",
            "\n",
            "epoch :  269 / 700\n",
            "train_acc = 36.088\n",
            "test_acc = 36.66\n",
            "loss = 1.8367358460041465\n",
            "\n",
            "epoch :  270 / 700\n",
            "train_acc = 36.108000000000004\n",
            "test_acc = 36.66\n",
            "loss = 1.8363338479141198\n",
            "\n",
            "epoch :  271 / 700\n",
            "train_acc = 36.114000000000004\n",
            "test_acc = 36.66\n",
            "loss = 1.8359335486693287\n",
            "\n",
            "epoch :  272 / 700\n",
            "train_acc = 36.126000000000005\n",
            "test_acc = 36.71\n",
            "loss = 1.8355349326494625\n",
            "\n",
            "epoch :  273 / 700\n",
            "train_acc = 36.146\n",
            "test_acc = 36.730000000000004\n",
            "loss = 1.8351379842929505\n",
            "\n",
            "epoch :  274 / 700\n",
            "train_acc = 36.164\n",
            "test_acc = 36.730000000000004\n",
            "loss = 1.834742688104795\n",
            "\n",
            "epoch :  275 / 700\n",
            "train_acc = 36.164\n",
            "test_acc = 36.730000000000004\n",
            "loss = 1.8343490286643025\n",
            "\n",
            "epoch :  276 / 700\n",
            "train_acc = 36.174\n",
            "test_acc = 36.75\n",
            "loss = 1.8339569906326376\n",
            "\n",
            "epoch :  277 / 700\n",
            "train_acc = 36.202\n",
            "test_acc = 36.74\n",
            "loss = 1.8335665587601777\n",
            "\n",
            "epoch :  278 / 700\n",
            "train_acc = 36.21\n",
            "test_acc = 36.79\n",
            "loss = 1.8331777178936046\n",
            "\n",
            "epoch :  279 / 700\n",
            "train_acc = 36.224000000000004\n",
            "test_acc = 36.84\n",
            "loss = 1.8327904529827066\n",
            "\n",
            "epoch :  280 / 700\n",
            "train_acc = 36.236000000000004\n",
            "test_acc = 36.870000000000005\n",
            "loss = 1.8324047490868594\n",
            "\n",
            "epoch :  281 / 700\n",
            "train_acc = 36.244\n",
            "test_acc = 36.86\n",
            "loss = 1.832020591381158\n",
            "\n",
            "epoch :  282 / 700\n",
            "train_acc = 36.256\n",
            "test_acc = 36.870000000000005\n",
            "loss = 1.8316379651621797\n",
            "\n",
            "epoch :  283 / 700\n",
            "train_acc = 36.262\n",
            "test_acc = 36.91\n",
            "loss = 1.8312568558533677\n",
            "\n",
            "epoch :  284 / 700\n",
            "train_acc = 36.284\n",
            "test_acc = 36.88\n",
            "loss = 1.8308772490100156\n",
            "\n",
            "epoch :  285 / 700\n",
            "train_acc = 36.296\n",
            "test_acc = 36.91\n",
            "loss = 1.8304991303238543\n",
            "\n",
            "epoch :  286 / 700\n",
            "train_acc = 36.303999999999995\n",
            "test_acc = 36.9\n",
            "loss = 1.8301224856272338\n",
            "\n",
            "epoch :  287 / 700\n",
            "train_acc = 36.324\n",
            "test_acc = 36.94\n",
            "loss = 1.829747300896903\n",
            "\n",
            "epoch :  288 / 700\n",
            "train_acc = 36.336\n",
            "test_acc = 36.94\n",
            "loss = 1.8293735622573897\n",
            "\n",
            "epoch :  289 / 700\n",
            "train_acc = 36.344\n",
            "test_acc = 36.919999999999995\n",
            "loss = 1.829001255983989\n",
            "\n",
            "epoch :  290 / 700\n",
            "train_acc = 36.358000000000004\n",
            "test_acc = 36.91\n",
            "loss = 1.8286303685053664\n",
            "\n",
            "epoch :  291 / 700\n",
            "train_acc = 36.374\n",
            "test_acc = 36.95\n",
            "loss = 1.8282608864057892\n",
            "\n",
            "epoch :  292 / 700\n",
            "train_acc = 36.4\n",
            "test_acc = 36.95\n",
            "loss = 1.8278927964269973\n",
            "\n",
            "epoch :  293 / 700\n",
            "train_acc = 36.424\n",
            "test_acc = 36.95\n",
            "loss = 1.82752608546973\n",
            "\n",
            "epoch :  294 / 700\n",
            "train_acc = 36.437999999999995\n",
            "test_acc = 36.95\n",
            "loss = 1.8271607405949162\n",
            "\n",
            "epoch :  295 / 700\n",
            "train_acc = 36.448\n",
            "test_acc = 36.94\n",
            "loss = 1.8267967490245585\n",
            "\n",
            "epoch :  296 / 700\n",
            "train_acc = 36.458\n",
            "test_acc = 36.94\n",
            "loss = 1.8264340981423102\n",
            "\n",
            "epoch :  297 / 700\n",
            "train_acc = 36.476\n",
            "test_acc = 36.97\n",
            "loss = 1.8260727754937787\n",
            "\n",
            "epoch :  298 / 700\n",
            "train_acc = 36.504\n",
            "test_acc = 36.980000000000004\n",
            "loss = 1.8257127687865595\n",
            "\n",
            "epoch :  299 / 700\n",
            "train_acc = 36.516\n",
            "test_acc = 36.980000000000004\n",
            "loss = 1.825354065890028\n",
            "\n",
            "epoch :  300 / 700\n",
            "train_acc = 36.524\n",
            "test_acc = 36.980000000000004\n",
            "loss = 1.8249966548349026\n",
            "\n",
            "epoch :  301 / 700\n",
            "train_acc = 36.528\n",
            "test_acc = 36.97\n",
            "loss = 1.8246405238125911\n",
            "\n",
            "epoch :  302 / 700\n",
            "train_acc = 36.54\n",
            "test_acc = 36.97\n",
            "loss = 1.8242856611743479\n",
            "\n",
            "epoch :  303 / 700\n",
            "train_acc = 36.568\n",
            "test_acc = 36.99\n",
            "loss = 1.8239320554302498\n",
            "\n",
            "epoch :  304 / 700\n",
            "train_acc = 36.574\n",
            "test_acc = 36.99\n",
            "loss = 1.8235796952480088\n",
            "\n",
            "epoch :  305 / 700\n",
            "train_acc = 36.594\n",
            "test_acc = 37.019999999999996\n",
            "loss = 1.8232285694516388\n",
            "\n",
            "epoch :  306 / 700\n",
            "train_acc = 36.612\n",
            "test_acc = 37.019999999999996\n",
            "loss = 1.8228786670199868\n",
            "\n",
            "epoch :  307 / 700\n",
            "train_acc = 36.638\n",
            "test_acc = 37.0\n",
            "loss = 1.8225299770851493\n",
            "\n",
            "epoch :  308 / 700\n",
            "train_acc = 36.652\n",
            "test_acc = 37.0\n",
            "loss = 1.822182488930777\n",
            "\n",
            "epoch :  309 / 700\n",
            "train_acc = 36.66\n",
            "test_acc = 37.0\n",
            "loss = 1.821836191990294\n",
            "\n",
            "epoch :  310 / 700\n",
            "train_acc = 36.686\n",
            "test_acc = 36.97\n",
            "loss = 1.8214910758450285\n",
            "\n",
            "epoch :  311 / 700\n",
            "train_acc = 36.681999999999995\n",
            "test_acc = 36.99\n",
            "loss = 1.8211471302222781\n",
            "\n",
            "epoch :  312 / 700\n",
            "train_acc = 36.702\n",
            "test_acc = 37.03\n",
            "loss = 1.820804344993316\n",
            "\n",
            "epoch :  313 / 700\n",
            "train_acc = 36.720000000000006\n",
            "test_acc = 37.04\n",
            "loss = 1.8204627101713415\n",
            "\n",
            "epoch :  314 / 700\n",
            "train_acc = 36.746\n",
            "test_acc = 37.03\n",
            "loss = 1.8201222159093984\n",
            "\n",
            "epoch :  315 / 700\n",
            "train_acc = 36.758\n",
            "test_acc = 37.04\n",
            "loss = 1.8197828524982536\n",
            "\n",
            "epoch :  316 / 700\n",
            "train_acc = 36.772\n",
            "test_acc = 37.059999999999995\n",
            "loss = 1.8194446103642576\n",
            "\n",
            "epoch :  317 / 700\n",
            "train_acc = 36.775999999999996\n",
            "test_acc = 37.019999999999996\n",
            "loss = 1.8191074800671814\n",
            "\n",
            "epoch :  318 / 700\n",
            "train_acc = 36.79\n",
            "test_acc = 37.03\n",
            "loss = 1.8187714522980472\n",
            "\n",
            "epoch :  319 / 700\n",
            "train_acc = 36.809999999999995\n",
            "test_acc = 37.04\n",
            "loss = 1.8184365178769537\n",
            "\n",
            "epoch :  320 / 700\n",
            "train_acc = 36.83\n",
            "test_acc = 37.05\n",
            "loss = 1.8181026677509002\n",
            "\n",
            "epoch :  321 / 700\n",
            "train_acc = 36.844\n",
            "test_acc = 37.059999999999995\n",
            "loss = 1.8177698929916186\n",
            "\n",
            "epoch :  322 / 700\n",
            "train_acc = 36.858000000000004\n",
            "test_acc = 37.08\n",
            "loss = 1.8174381847934133\n",
            "\n",
            "epoch :  323 / 700\n",
            "train_acc = 36.876\n",
            "test_acc = 37.08\n",
            "loss = 1.8171075344710181\n",
            "\n",
            "epoch :  324 / 700\n",
            "train_acc = 36.888\n",
            "test_acc = 37.09\n",
            "loss = 1.8167779334574683\n",
            "\n",
            "epoch :  325 / 700\n",
            "train_acc = 36.91\n",
            "test_acc = 37.13\n",
            "loss = 1.8164493733019944\n",
            "\n",
            "epoch :  326 / 700\n",
            "train_acc = 36.931999999999995\n",
            "test_acc = 37.12\n",
            "loss = 1.8161218456679422\n",
            "\n",
            "epoch :  327 / 700\n",
            "train_acc = 36.95\n",
            "test_acc = 37.12\n",
            "loss = 1.815795342330712\n",
            "\n",
            "epoch :  328 / 700\n",
            "train_acc = 36.962\n",
            "test_acc = 37.12\n",
            "loss = 1.8154698551757376\n",
            "\n",
            "epoch :  329 / 700\n",
            "train_acc = 36.974000000000004\n",
            "test_acc = 37.12\n",
            "loss = 1.815145376196483\n",
            "\n",
            "epoch :  330 / 700\n",
            "train_acc = 36.980000000000004\n",
            "test_acc = 37.15\n",
            "loss = 1.814821897492479\n",
            "\n",
            "epoch :  331 / 700\n",
            "train_acc = 36.980000000000004\n",
            "test_acc = 37.15\n",
            "loss = 1.8144994112673924\n",
            "\n",
            "epoch :  332 / 700\n",
            "train_acc = 37.0\n",
            "test_acc = 37.19\n",
            "loss = 1.8141779098271245\n",
            "\n",
            "epoch :  333 / 700\n",
            "train_acc = 37.0\n",
            "test_acc = 37.21\n",
            "loss = 1.8138573855779498\n",
            "\n",
            "epoch :  334 / 700\n",
            "train_acc = 37.004\n",
            "test_acc = 37.24\n",
            "loss = 1.8135378310246881\n",
            "\n",
            "epoch :  335 / 700\n",
            "train_acc = 37.01\n",
            "test_acc = 37.230000000000004\n",
            "loss = 1.813219238768912\n",
            "\n",
            "epoch :  336 / 700\n",
            "train_acc = 37.024\n",
            "test_acc = 37.25\n",
            "loss = 1.812901601507193\n",
            "\n",
            "epoch :  337 / 700\n",
            "train_acc = 37.019999999999996\n",
            "test_acc = 37.25\n",
            "loss = 1.8125849120293842\n",
            "\n",
            "epoch :  338 / 700\n",
            "train_acc = 37.03\n",
            "test_acc = 37.269999999999996\n",
            "loss = 1.8122691632169357\n",
            "\n",
            "epoch :  339 / 700\n",
            "train_acc = 37.038\n",
            "test_acc = 37.29\n",
            "loss = 1.811954348041253\n",
            "\n",
            "epoch :  340 / 700\n",
            "train_acc = 37.05\n",
            "test_acc = 37.3\n",
            "loss = 1.8116404595620876\n",
            "\n",
            "epoch :  341 / 700\n",
            "train_acc = 37.072\n",
            "test_acc = 37.3\n",
            "loss = 1.8113274909259651\n",
            "\n",
            "epoch :  342 / 700\n",
            "train_acc = 37.088\n",
            "test_acc = 37.35\n",
            "loss = 1.8110154353646475\n",
            "\n",
            "epoch :  343 / 700\n",
            "train_acc = 37.1\n",
            "test_acc = 37.35\n",
            "loss = 1.8107042861936353\n",
            "\n",
            "epoch :  344 / 700\n",
            "train_acc = 37.12\n",
            "test_acc = 37.36\n",
            "loss = 1.8103940368107012\n",
            "\n",
            "epoch :  345 / 700\n",
            "train_acc = 37.13\n",
            "test_acc = 37.36\n",
            "loss = 1.810084680694456\n",
            "\n",
            "epoch :  346 / 700\n",
            "train_acc = 37.15\n",
            "test_acc = 37.38\n",
            "loss = 1.8097762114029543\n",
            "\n",
            "epoch :  347 / 700\n",
            "train_acc = 37.158\n",
            "test_acc = 37.39\n",
            "loss = 1.809468622572328\n",
            "\n",
            "epoch :  348 / 700\n",
            "train_acc = 37.158\n",
            "test_acc = 37.4\n",
            "loss = 1.8091619079154568\n",
            "\n",
            "epoch :  349 / 700\n",
            "train_acc = 37.164\n",
            "test_acc = 37.4\n",
            "loss = 1.8088560612206661\n",
            "\n",
            "epoch :  350 / 700\n",
            "train_acc = 37.186\n",
            "test_acc = 37.4\n",
            "loss = 1.8085510763504584\n",
            "\n",
            "epoch :  351 / 700\n",
            "train_acc = 37.194\n",
            "test_acc = 37.39\n",
            "loss = 1.808246947240275\n",
            "\n",
            "epoch :  352 / 700\n",
            "train_acc = 37.208000000000006\n",
            "test_acc = 37.419999999999995\n",
            "loss = 1.8079436678972844\n",
            "\n",
            "epoch :  353 / 700\n",
            "train_acc = 37.218\n",
            "test_acc = 37.44\n",
            "loss = 1.8076412323992077\n",
            "\n",
            "epoch :  354 / 700\n",
            "train_acc = 37.234\n",
            "test_acc = 37.46\n",
            "loss = 1.8073396348931583\n",
            "\n",
            "epoch :  355 / 700\n",
            "train_acc = 37.242\n",
            "test_acc = 37.43\n",
            "loss = 1.8070388695945225\n",
            "\n",
            "epoch :  356 / 700\n",
            "train_acc = 37.254\n",
            "test_acc = 37.419999999999995\n",
            "loss = 1.8067389307858572\n",
            "\n",
            "epoch :  357 / 700\n",
            "train_acc = 37.269999999999996\n",
            "test_acc = 37.419999999999995\n",
            "loss = 1.806439812815818\n",
            "\n",
            "epoch :  358 / 700\n",
            "train_acc = 37.296\n",
            "test_acc = 37.43\n",
            "loss = 1.8061415100981102\n",
            "\n",
            "epoch :  359 / 700\n",
            "train_acc = 37.308\n",
            "test_acc = 37.419999999999995\n",
            "loss = 1.805844017110464\n",
            "\n",
            "epoch :  360 / 700\n",
            "train_acc = 37.314\n",
            "test_acc = 37.41\n",
            "loss = 1.8055473283936327\n",
            "\n",
            "epoch :  361 / 700\n",
            "train_acc = 37.314\n",
            "test_acc = 37.43\n",
            "loss = 1.8052514385504164\n",
            "\n",
            "epoch :  362 / 700\n",
            "train_acc = 37.324\n",
            "test_acc = 37.45\n",
            "loss = 1.8049563422447008\n",
            "\n",
            "epoch :  363 / 700\n",
            "train_acc = 37.334\n",
            "test_acc = 37.45\n",
            "loss = 1.8046620342005255\n",
            "\n",
            "epoch :  364 / 700\n",
            "train_acc = 37.352000000000004\n",
            "test_acc = 37.46\n",
            "loss = 1.8043685092011663\n",
            "\n",
            "epoch :  365 / 700\n",
            "train_acc = 37.356\n",
            "test_acc = 37.47\n",
            "loss = 1.8040757620882375\n",
            "\n",
            "epoch :  366 / 700\n",
            "train_acc = 37.36\n",
            "test_acc = 37.49\n",
            "loss = 1.8037837877608187\n",
            "\n",
            "epoch :  367 / 700\n",
            "train_acc = 37.378\n",
            "test_acc = 37.54\n",
            "loss = 1.8034925811745939\n",
            "\n",
            "epoch :  368 / 700\n",
            "train_acc = 37.38\n",
            "test_acc = 37.53\n",
            "loss = 1.8032021373410088\n",
            "\n",
            "epoch :  369 / 700\n",
            "train_acc = 37.39\n",
            "test_acc = 37.57\n",
            "loss = 1.8029124513264503\n",
            "\n",
            "epoch :  370 / 700\n",
            "train_acc = 37.413999999999994\n",
            "test_acc = 37.56\n",
            "loss = 1.802623518251436\n",
            "\n",
            "epoch :  371 / 700\n",
            "train_acc = 37.41\n",
            "test_acc = 37.61\n",
            "loss = 1.802335333289821\n",
            "\n",
            "epoch :  372 / 700\n",
            "train_acc = 37.419999999999995\n",
            "test_acc = 37.6\n",
            "loss = 1.802047891668027\n",
            "\n",
            "epoch :  373 / 700\n",
            "train_acc = 37.425999999999995\n",
            "test_acc = 37.61\n",
            "loss = 1.8017611886642717\n",
            "\n",
            "epoch :  374 / 700\n",
            "train_acc = 37.438\n",
            "test_acc = 37.64\n",
            "loss = 1.8014752196078292\n",
            "\n",
            "epoch :  375 / 700\n",
            "train_acc = 37.458000000000006\n",
            "test_acc = 37.669999999999995\n",
            "loss = 1.8011899798782882\n",
            "\n",
            "epoch :  376 / 700\n",
            "train_acc = 37.456\n",
            "test_acc = 37.68\n",
            "loss = 1.8009054649048357\n",
            "\n",
            "epoch :  377 / 700\n",
            "train_acc = 37.47\n",
            "test_acc = 37.669999999999995\n",
            "loss = 1.8006216701655462\n",
            "\n",
            "epoch :  378 / 700\n",
            "train_acc = 37.480000000000004\n",
            "test_acc = 37.65\n",
            "loss = 1.8003385911866838\n",
            "\n",
            "epoch :  379 / 700\n",
            "train_acc = 37.478\n",
            "test_acc = 37.66\n",
            "loss = 1.80005622354202\n",
            "\n",
            "epoch :  380 / 700\n",
            "train_acc = 37.478\n",
            "test_acc = 37.669999999999995\n",
            "loss = 1.7997745628521578\n",
            "\n",
            "epoch :  381 / 700\n",
            "train_acc = 37.484\n",
            "test_acc = 37.669999999999995\n",
            "loss = 1.7994936047838694\n",
            "\n",
            "epoch :  382 / 700\n",
            "train_acc = 37.494\n",
            "test_acc = 37.7\n",
            "loss = 1.7992133450494432\n",
            "\n",
            "epoch :  383 / 700\n",
            "train_acc = 37.5\n",
            "test_acc = 37.71\n",
            "loss = 1.7989337794060416\n",
            "\n",
            "epoch :  384 / 700\n",
            "train_acc = 37.512\n",
            "test_acc = 37.7\n",
            "loss = 1.798654903655069\n",
            "\n",
            "epoch :  385 / 700\n",
            "train_acc = 37.513999999999996\n",
            "test_acc = 37.7\n",
            "loss = 1.7983767136415458\n",
            "\n",
            "epoch :  386 / 700\n",
            "train_acc = 37.522\n",
            "test_acc = 37.7\n",
            "loss = 1.7980992052534972\n",
            "\n",
            "epoch :  387 / 700\n",
            "train_acc = 37.546\n",
            "test_acc = 37.7\n",
            "loss = 1.7978223744213446\n",
            "\n",
            "epoch :  388 / 700\n",
            "train_acc = 37.55\n",
            "test_acc = 37.730000000000004\n",
            "loss = 1.7975462171173098\n",
            "\n",
            "epoch :  389 / 700\n",
            "train_acc = 37.554\n",
            "test_acc = 37.76\n",
            "loss = 1.7972707293548236\n",
            "\n",
            "epoch :  390 / 700\n",
            "train_acc = 37.562\n",
            "test_acc = 37.769999999999996\n",
            "loss = 1.7969959071879475\n",
            "\n",
            "epoch :  391 / 700\n",
            "train_acc = 37.578\n",
            "test_acc = 37.79\n",
            "loss = 1.7967217467107963\n",
            "\n",
            "epoch :  392 / 700\n",
            "train_acc = 37.580000000000005\n",
            "test_acc = 37.8\n",
            "loss = 1.7964482440569731\n",
            "\n",
            "epoch :  393 / 700\n",
            "train_acc = 37.584\n",
            "test_acc = 37.8\n",
            "loss = 1.7961753953990098\n",
            "\n",
            "epoch :  394 / 700\n",
            "train_acc = 37.596000000000004\n",
            "test_acc = 37.79\n",
            "loss = 1.7959031969478132\n",
            "\n",
            "epoch :  395 / 700\n",
            "train_acc = 37.618\n",
            "test_acc = 37.79\n",
            "loss = 1.7956316449521201\n",
            "\n",
            "epoch :  396 / 700\n",
            "train_acc = 37.632\n",
            "test_acc = 37.79\n",
            "loss = 1.7953607356979568\n",
            "\n",
            "epoch :  397 / 700\n",
            "train_acc = 37.634\n",
            "test_acc = 37.79\n",
            "loss = 1.7950904655081061\n",
            "\n",
            "epoch :  398 / 700\n",
            "train_acc = 37.64\n",
            "test_acc = 37.79\n",
            "loss = 1.7948208307415796\n",
            "\n",
            "epoch :  399 / 700\n",
            "train_acc = 37.666\n",
            "test_acc = 37.79\n",
            "loss = 1.7945518277930967\n",
            "\n",
            "epoch :  400 / 700\n",
            "train_acc = 37.678\n",
            "test_acc = 37.81\n",
            "loss = 1.7942834530925684\n",
            "\n",
            "epoch :  401 / 700\n",
            "train_acc = 37.686\n",
            "test_acc = 37.82\n",
            "loss = 1.7940157031045891\n",
            "\n",
            "epoch :  402 / 700\n",
            "train_acc = 37.714\n",
            "test_acc = 37.84\n",
            "loss = 1.7937485743279293\n",
            "\n",
            "epoch :  403 / 700\n",
            "train_acc = 37.7\n",
            "test_acc = 37.84\n",
            "loss = 1.7934820632950392\n",
            "\n",
            "epoch :  404 / 700\n",
            "train_acc = 37.718\n",
            "test_acc = 37.85\n",
            "loss = 1.7932161665715547\n",
            "\n",
            "epoch :  405 / 700\n",
            "train_acc = 37.728\n",
            "test_acc = 37.830000000000005\n",
            "loss = 1.7929508807558063\n",
            "\n",
            "epoch :  406 / 700\n",
            "train_acc = 37.746\n",
            "test_acc = 37.830000000000005\n",
            "loss = 1.7926862024783403\n",
            "\n",
            "epoch :  407 / 700\n",
            "train_acc = 37.744\n",
            "test_acc = 37.84\n",
            "loss = 1.7924221284014357\n",
            "\n",
            "epoch :  408 / 700\n",
            "train_acc = 37.76\n",
            "test_acc = 37.87\n",
            "loss = 1.7921586552186337\n",
            "\n",
            "epoch :  409 / 700\n",
            "train_acc = 37.775999999999996\n",
            "test_acc = 37.89\n",
            "loss = 1.7918957796542685\n",
            "\n",
            "epoch :  410 / 700\n",
            "train_acc = 37.785999999999994\n",
            "test_acc = 37.9\n",
            "loss = 1.7916334984630031\n",
            "\n",
            "epoch :  411 / 700\n",
            "train_acc = 37.796\n",
            "test_acc = 37.91\n",
            "loss = 1.791371808429371\n",
            "\n",
            "epoch :  412 / 700\n",
            "train_acc = 37.802\n",
            "test_acc = 37.91\n",
            "loss = 1.7911107063673217\n",
            "\n",
            "epoch :  413 / 700\n",
            "train_acc = 37.816\n",
            "test_acc = 37.91\n",
            "loss = 1.7908501891197701\n",
            "\n",
            "epoch :  414 / 700\n",
            "train_acc = 37.834\n",
            "test_acc = 37.93\n",
            "loss = 1.7905902535581546\n",
            "\n",
            "epoch :  415 / 700\n",
            "train_acc = 37.838\n",
            "test_acc = 37.96\n",
            "loss = 1.7903308965819926\n",
            "\n",
            "epoch :  416 / 700\n",
            "train_acc = 37.84\n",
            "test_acc = 37.96\n",
            "loss = 1.7900721151184484\n",
            "\n",
            "epoch :  417 / 700\n",
            "train_acc = 37.844\n",
            "test_acc = 37.97\n",
            "loss = 1.7898139061219005\n",
            "\n",
            "epoch :  418 / 700\n",
            "train_acc = 37.854\n",
            "test_acc = 37.96\n",
            "loss = 1.789556266573515\n",
            "\n",
            "epoch :  419 / 700\n",
            "train_acc = 37.868\n",
            "test_acc = 37.96\n",
            "loss = 1.7892991934808236\n",
            "\n",
            "epoch :  420 / 700\n",
            "train_acc = 37.872\n",
            "test_acc = 37.96\n",
            "loss = 1.7890426838773075\n",
            "\n",
            "epoch :  421 / 700\n",
            "train_acc = 37.876\n",
            "test_acc = 37.97\n",
            "loss = 1.7887867348219826\n",
            "\n",
            "epoch :  422 / 700\n",
            "train_acc = 37.891999999999996\n",
            "test_acc = 38.0\n",
            "loss = 1.7885313433989927\n",
            "\n",
            "epoch :  423 / 700\n",
            "train_acc = 37.902\n",
            "test_acc = 38.0\n",
            "loss = 1.7882765067172053\n",
            "\n",
            "epoch :  424 / 700\n",
            "train_acc = 37.912\n",
            "test_acc = 37.99\n",
            "loss = 1.7880222219098127\n",
            "\n",
            "epoch :  425 / 700\n",
            "train_acc = 37.912\n",
            "test_acc = 38.0\n",
            "loss = 1.7877684861339371\n",
            "\n",
            "epoch :  426 / 700\n",
            "train_acc = 37.92\n",
            "test_acc = 38.0\n",
            "loss = 1.7875152965702403\n",
            "\n",
            "epoch :  427 / 700\n",
            "train_acc = 37.93\n",
            "test_acc = 38.0\n",
            "loss = 1.7872626504225404\n",
            "\n",
            "epoch :  428 / 700\n",
            "train_acc = 37.936\n",
            "test_acc = 38.01\n",
            "loss = 1.7870105449174287\n",
            "\n",
            "epoch :  429 / 700\n",
            "train_acc = 37.938\n",
            "test_acc = 38.01\n",
            "loss = 1.7867589773038959\n",
            "\n",
            "epoch :  430 / 700\n",
            "train_acc = 37.932\n",
            "test_acc = 38.04\n",
            "loss = 1.7865079448529602\n",
            "\n",
            "epoch :  431 / 700\n",
            "train_acc = 37.946000000000005\n",
            "test_acc = 38.07\n",
            "loss = 1.7862574448572996\n",
            "\n",
            "epoch :  432 / 700\n",
            "train_acc = 37.948\n",
            "test_acc = 38.080000000000005\n",
            "loss = 1.7860074746308943\n",
            "\n",
            "epoch :  433 / 700\n",
            "train_acc = 37.95\n",
            "test_acc = 38.080000000000005\n",
            "loss = 1.7857580315086632\n",
            "\n",
            "epoch :  434 / 700\n",
            "train_acc = 37.96\n",
            "test_acc = 38.1\n",
            "loss = 1.7855091128461198\n",
            "\n",
            "epoch :  435 / 700\n",
            "train_acc = 37.964\n",
            "test_acc = 38.09\n",
            "loss = 1.7852607160190177\n",
            "\n",
            "epoch :  436 / 700\n",
            "train_acc = 37.97\n",
            "test_acc = 38.09\n",
            "loss = 1.7850128384230142\n",
            "\n",
            "epoch :  437 / 700\n",
            "train_acc = 37.998\n",
            "test_acc = 38.129999999999995\n",
            "loss = 1.7847654774733295\n",
            "\n",
            "epoch :  438 / 700\n",
            "train_acc = 38.01\n",
            "test_acc = 38.129999999999995\n",
            "loss = 1.7845186306044158\n",
            "\n",
            "epoch :  439 / 700\n",
            "train_acc = 38.028\n",
            "test_acc = 38.16\n",
            "loss = 1.7842722952696293\n",
            "\n",
            "epoch :  440 / 700\n",
            "train_acc = 38.038\n",
            "test_acc = 38.15\n",
            "loss = 1.7840264689409089\n",
            "\n",
            "epoch :  441 / 700\n",
            "train_acc = 38.044\n",
            "test_acc = 38.14\n",
            "loss = 1.7837811491084579\n",
            "\n",
            "epoch :  442 / 700\n",
            "train_acc = 38.058\n",
            "test_acc = 38.15\n",
            "loss = 1.783536333280432\n",
            "\n",
            "epoch :  443 / 700\n",
            "train_acc = 38.074000000000005\n",
            "test_acc = 38.15\n",
            "loss = 1.7832920189826338\n",
            "\n",
            "epoch :  444 / 700\n",
            "train_acc = 38.074000000000005\n",
            "test_acc = 38.15\n",
            "loss = 1.783048203758208\n",
            "\n",
            "epoch :  445 / 700\n",
            "train_acc = 38.086\n",
            "test_acc = 38.16\n",
            "loss = 1.7828048851673457\n",
            "\n",
            "epoch :  446 / 700\n",
            "train_acc = 38.102000000000004\n",
            "test_acc = 38.16\n",
            "loss = 1.7825620607869974\n",
            "\n",
            "epoch :  447 / 700\n",
            "train_acc = 38.114\n",
            "test_acc = 38.18\n",
            "loss = 1.7823197282105783\n",
            "\n",
            "epoch :  448 / 700\n",
            "train_acc = 38.138\n",
            "test_acc = 38.2\n",
            "loss = 1.782077885047693\n",
            "\n",
            "epoch :  449 / 700\n",
            "train_acc = 38.147999999999996\n",
            "test_acc = 38.2\n",
            "loss = 1.7818365289238594\n",
            "\n",
            "epoch :  450 / 700\n",
            "train_acc = 38.157999999999994\n",
            "test_acc = 38.2\n",
            "loss = 1.781595657480236\n",
            "\n",
            "epoch :  451 / 700\n",
            "train_acc = 38.17\n",
            "test_acc = 38.21\n",
            "loss = 1.7813552683733578\n",
            "\n",
            "epoch :  452 / 700\n",
            "train_acc = 38.192\n",
            "test_acc = 38.21\n",
            "loss = 1.781115359274876\n",
            "\n",
            "epoch :  453 / 700\n",
            "train_acc = 38.190000000000005\n",
            "test_acc = 38.21\n",
            "loss = 1.780875927871304\n",
            "\n",
            "epoch :  454 / 700\n",
            "train_acc = 38.18\n",
            "test_acc = 38.2\n",
            "loss = 1.7806369718637673\n",
            "\n",
            "epoch :  455 / 700\n",
            "train_acc = 38.184000000000005\n",
            "test_acc = 38.21\n",
            "loss = 1.7803984889677602\n",
            "\n",
            "epoch :  456 / 700\n",
            "train_acc = 38.192\n",
            "test_acc = 38.190000000000005\n",
            "loss = 1.780160476912907\n",
            "\n",
            "epoch :  457 / 700\n",
            "train_acc = 38.2\n",
            "test_acc = 38.190000000000005\n",
            "loss = 1.779922933442727\n",
            "\n",
            "epoch :  458 / 700\n",
            "train_acc = 38.216\n",
            "test_acc = 38.190000000000005\n",
            "loss = 1.7796858563144102\n",
            "\n",
            "epoch :  459 / 700\n",
            "train_acc = 38.224000000000004\n",
            "test_acc = 38.190000000000005\n",
            "loss = 1.7794492432985907\n",
            "\n",
            "epoch :  460 / 700\n",
            "train_acc = 38.244\n",
            "test_acc = 38.21\n",
            "loss = 1.7792130921791323\n",
            "\n",
            "epoch :  461 / 700\n",
            "train_acc = 38.262\n",
            "test_acc = 38.22\n",
            "loss = 1.7789774007529158\n",
            "\n",
            "epoch :  462 / 700\n",
            "train_acc = 38.272\n",
            "test_acc = 38.21\n",
            "loss = 1.7787421668296317\n",
            "\n",
            "epoch :  463 / 700\n",
            "train_acc = 38.274\n",
            "test_acc = 38.18\n",
            "loss = 1.778507388231578\n",
            "\n",
            "epoch :  464 / 700\n",
            "train_acc = 38.278\n",
            "test_acc = 38.2\n",
            "loss = 1.7782730627934673\n",
            "\n",
            "epoch :  465 / 700\n",
            "train_acc = 38.306000000000004\n",
            "test_acc = 38.22\n",
            "loss = 1.7780391883622335\n",
            "\n",
            "epoch :  466 / 700\n",
            "train_acc = 38.308\n",
            "test_acc = 38.24\n",
            "loss = 1.777805762796846\n",
            "\n",
            "epoch :  467 / 700\n",
            "train_acc = 38.312000000000005\n",
            "test_acc = 38.24\n",
            "loss = 1.7775727839681321\n",
            "\n",
            "epoch :  468 / 700\n",
            "train_acc = 38.322\n",
            "test_acc = 38.25\n",
            "loss = 1.7773402497585982\n",
            "\n",
            "epoch :  469 / 700\n",
            "train_acc = 38.322\n",
            "test_acc = 38.25\n",
            "loss = 1.7771081580622636\n",
            "\n",
            "epoch :  470 / 700\n",
            "train_acc = 38.328\n",
            "test_acc = 38.279999999999994\n",
            "loss = 1.7768765067844918\n",
            "\n",
            "epoch :  471 / 700\n",
            "train_acc = 38.336\n",
            "test_acc = 38.3\n",
            "loss = 1.7766452938418351\n",
            "\n",
            "epoch :  472 / 700\n",
            "train_acc = 38.346000000000004\n",
            "test_acc = 38.32\n",
            "loss = 1.7764145171618757\n",
            "\n",
            "epoch :  473 / 700\n",
            "train_acc = 38.368\n",
            "test_acc = 38.34\n",
            "loss = 1.7761841746830804\n",
            "\n",
            "epoch :  474 / 700\n",
            "train_acc = 38.37\n",
            "test_acc = 38.34\n",
            "loss = 1.7759542643546524\n",
            "\n",
            "epoch :  475 / 700\n",
            "train_acc = 38.374\n",
            "test_acc = 38.34\n",
            "loss = 1.7757247841363926\n",
            "\n",
            "epoch :  476 / 700\n",
            "train_acc = 38.382\n",
            "test_acc = 38.34\n",
            "loss = 1.7754957319985658\n",
            "\n",
            "epoch :  477 / 700\n",
            "train_acc = 38.374\n",
            "test_acc = 38.36\n",
            "loss = 1.7752671059217697\n",
            "\n",
            "epoch :  478 / 700\n",
            "train_acc = 38.378\n",
            "test_acc = 38.39\n",
            "loss = 1.775038903896811\n",
            "\n",
            "epoch :  479 / 700\n",
            "train_acc = 38.384\n",
            "test_acc = 38.4\n",
            "loss = 1.7748111239245832\n",
            "\n",
            "epoch :  480 / 700\n",
            "train_acc = 38.396\n",
            "test_acc = 38.41\n",
            "loss = 1.7745837640159514\n",
            "\n",
            "epoch :  481 / 700\n",
            "train_acc = 38.396\n",
            "test_acc = 38.4\n",
            "loss = 1.774356822191641\n",
            "\n",
            "epoch :  482 / 700\n",
            "train_acc = 38.401999999999994\n",
            "test_acc = 38.42\n",
            "loss = 1.774130296482133\n",
            "\n",
            "epoch :  483 / 700\n",
            "train_acc = 38.418\n",
            "test_acc = 38.41\n",
            "loss = 1.773904184927557\n",
            "\n",
            "epoch :  484 / 700\n",
            "train_acc = 38.436\n",
            "test_acc = 38.43\n",
            "loss = 1.7736784855776\n",
            "\n",
            "epoch :  485 / 700\n",
            "train_acc = 38.440000000000005\n",
            "test_acc = 38.440000000000005\n",
            "loss = 1.7734531964914053\n",
            "\n",
            "epoch :  486 / 700\n",
            "train_acc = 38.448\n",
            "test_acc = 38.440000000000005\n",
            "loss = 1.7732283157374915\n",
            "\n",
            "epoch :  487 / 700\n",
            "train_acc = 38.45\n",
            "test_acc = 38.440000000000005\n",
            "loss = 1.7730038413936597\n",
            "\n",
            "epoch :  488 / 700\n",
            "train_acc = 38.45\n",
            "test_acc = 38.46\n",
            "loss = 1.7727797715469176\n",
            "\n",
            "epoch :  489 / 700\n",
            "train_acc = 38.454\n",
            "test_acc = 38.47\n",
            "loss = 1.7725561042934004\n",
            "\n",
            "epoch :  490 / 700\n",
            "train_acc = 38.456\n",
            "test_acc = 38.49\n",
            "loss = 1.7723328377382974\n",
            "\n",
            "epoch :  491 / 700\n",
            "train_acc = 38.464\n",
            "test_acc = 38.5\n",
            "loss = 1.7721099699957856\n",
            "\n",
            "epoch :  492 / 700\n",
            "train_acc = 38.476\n",
            "test_acc = 38.51\n",
            "loss = 1.7718874991889597\n",
            "\n",
            "epoch :  493 / 700\n",
            "train_acc = 38.484\n",
            "test_acc = 38.5\n",
            "loss = 1.7716654234497748\n",
            "\n",
            "epoch :  494 / 700\n",
            "train_acc = 38.494\n",
            "test_acc = 38.519999999999996\n",
            "loss = 1.7714437409189843\n",
            "\n",
            "epoch :  495 / 700\n",
            "train_acc = 38.498\n",
            "test_acc = 38.51\n",
            "loss = 1.7712224497460887\n",
            "\n",
            "epoch :  496 / 700\n",
            "train_acc = 38.51\n",
            "test_acc = 38.54\n",
            "loss = 1.7710015480892813\n",
            "\n",
            "epoch :  497 / 700\n",
            "train_acc = 38.522\n",
            "test_acc = 38.57\n",
            "loss = 1.770781034115402\n",
            "\n",
            "epoch :  498 / 700\n",
            "train_acc = 38.53\n",
            "test_acc = 38.59\n",
            "loss = 1.7705609059998906\n",
            "\n",
            "epoch :  499 / 700\n",
            "train_acc = 38.554\n",
            "test_acc = 38.59\n",
            "loss = 1.7703411619267477\n",
            "\n",
            "epoch :  500 / 700\n",
            "train_acc = 38.57\n",
            "test_acc = 38.58\n",
            "loss = 1.7701218000884933\n",
            "\n",
            "epoch :  501 / 700\n",
            "train_acc = 38.574000000000005\n",
            "test_acc = 38.59\n",
            "loss = 1.7699028186861316\n",
            "\n",
            "epoch :  502 / 700\n",
            "train_acc = 38.574000000000005\n",
            "test_acc = 38.61\n",
            "loss = 1.7696842159291193\n",
            "\n",
            "epoch :  503 / 700\n",
            "train_acc = 38.582\n",
            "test_acc = 38.61\n",
            "loss = 1.7694659900353324\n",
            "\n",
            "epoch :  504 / 700\n",
            "train_acc = 38.596000000000004\n",
            "test_acc = 38.61\n",
            "loss = 1.7692481392310422\n",
            "\n",
            "epoch :  505 / 700\n",
            "train_acc = 38.602\n",
            "test_acc = 38.62\n",
            "loss = 1.7690306617508862\n",
            "\n",
            "epoch :  506 / 700\n",
            "train_acc = 38.608\n",
            "test_acc = 38.629999999999995\n",
            "loss = 1.7688135558378468\n",
            "\n",
            "epoch :  507 / 700\n",
            "train_acc = 38.616\n",
            "test_acc = 38.65\n",
            "loss = 1.7685968197432311\n",
            "\n",
            "epoch :  508 / 700\n",
            "train_acc = 38.628\n",
            "test_acc = 38.64\n",
            "loss = 1.7683804517266521\n",
            "\n",
            "epoch :  509 / 700\n",
            "train_acc = 38.634\n",
            "test_acc = 38.65\n",
            "loss = 1.7681644500560112\n",
            "\n",
            "epoch :  510 / 700\n",
            "train_acc = 38.638\n",
            "test_acc = 38.61\n",
            "loss = 1.7679488130074845\n",
            "\n",
            "epoch :  511 / 700\n",
            "train_acc = 38.65\n",
            "test_acc = 38.62\n",
            "loss = 1.7677335388655115\n",
            "\n",
            "epoch :  512 / 700\n",
            "train_acc = 38.653999999999996\n",
            "test_acc = 38.64\n",
            "loss = 1.7675186259227809\n",
            "\n",
            "epoch :  513 / 700\n",
            "train_acc = 38.666\n",
            "test_acc = 38.66\n",
            "loss = 1.7673040724802263\n",
            "\n",
            "epoch :  514 / 700\n",
            "train_acc = 38.672000000000004\n",
            "test_acc = 38.65\n",
            "loss = 1.7670898768470136\n",
            "\n",
            "epoch :  515 / 700\n",
            "train_acc = 38.668\n",
            "test_acc = 38.68\n",
            "loss = 1.7668760373405377\n",
            "\n",
            "epoch :  516 / 700\n",
            "train_acc = 38.676\n",
            "test_acc = 38.7\n",
            "loss = 1.766662552286417\n",
            "\n",
            "epoch :  517 / 700\n",
            "train_acc = 38.672000000000004\n",
            "test_acc = 38.72\n",
            "loss = 1.766449420018491\n",
            "\n",
            "epoch :  518 / 700\n",
            "train_acc = 38.678000000000004\n",
            "test_acc = 38.71\n",
            "loss = 1.766236638878815\n",
            "\n",
            "epoch :  519 / 700\n",
            "train_acc = 38.688\n",
            "test_acc = 38.73\n",
            "loss = 1.7660242072176626\n",
            "\n",
            "epoch :  520 / 700\n",
            "train_acc = 38.696000000000005\n",
            "test_acc = 38.73\n",
            "loss = 1.7658121233935227\n",
            "\n",
            "epoch :  521 / 700\n",
            "train_acc = 38.71\n",
            "test_acc = 38.75\n",
            "loss = 1.7656003857731009\n",
            "\n",
            "epoch :  522 / 700\n",
            "train_acc = 38.724\n",
            "test_acc = 38.76\n",
            "loss = 1.76538899273132\n",
            "\n",
            "epoch :  523 / 700\n",
            "train_acc = 38.726\n",
            "test_acc = 38.800000000000004\n",
            "loss = 1.7651779426513239\n",
            "\n",
            "epoch :  524 / 700\n",
            "train_acc = 38.734\n",
            "test_acc = 38.81\n",
            "loss = 1.7649672339244789\n",
            "\n",
            "epoch :  525 / 700\n",
            "train_acc = 38.744\n",
            "test_acc = 38.83\n",
            "loss = 1.764756864950376\n",
            "\n",
            "epoch :  526 / 700\n",
            "train_acc = 38.754\n",
            "test_acc = 38.87\n",
            "loss = 1.7645468341368378\n",
            "\n",
            "epoch :  527 / 700\n",
            "train_acc = 38.768\n",
            "test_acc = 38.879999999999995\n",
            "loss = 1.7643371398999188\n",
            "\n",
            "epoch :  528 / 700\n",
            "train_acc = 38.762\n",
            "test_acc = 38.89\n",
            "loss = 1.7641277806639108\n",
            "\n",
            "epoch :  529 / 700\n",
            "train_acc = 38.766\n",
            "test_acc = 38.89\n",
            "loss = 1.7639187548613486\n",
            "\n",
            "epoch :  530 / 700\n",
            "train_acc = 38.782\n",
            "test_acc = 38.879999999999995\n",
            "loss = 1.7637100609330132\n",
            "\n",
            "epoch :  531 / 700\n",
            "train_acc = 38.794000000000004\n",
            "test_acc = 38.92\n",
            "loss = 1.7635016973279374\n",
            "\n",
            "epoch :  532 / 700\n",
            "train_acc = 38.806000000000004\n",
            "test_acc = 38.92\n",
            "loss = 1.7632936625034081\n",
            "\n",
            "epoch :  533 / 700\n",
            "train_acc = 38.802\n",
            "test_acc = 38.93\n",
            "loss = 1.7630859549249736\n",
            "\n",
            "epoch :  534 / 700\n",
            "train_acc = 38.818000000000005\n",
            "test_acc = 38.93\n",
            "loss = 1.7628785730664478\n",
            "\n",
            "epoch :  535 / 700\n",
            "train_acc = 38.83\n",
            "test_acc = 38.940000000000005\n",
            "loss = 1.76267151540991\n",
            "\n",
            "epoch :  536 / 700\n",
            "train_acc = 38.848\n",
            "test_acc = 38.96\n",
            "loss = 1.7624647804457148\n",
            "\n",
            "epoch :  537 / 700\n",
            "train_acc = 38.856\n",
            "test_acc = 38.97\n",
            "loss = 1.762258366672492\n",
            "\n",
            "epoch :  538 / 700\n",
            "train_acc = 38.86\n",
            "test_acc = 38.97\n",
            "loss = 1.762052272597149\n",
            "\n",
            "epoch :  539 / 700\n",
            "train_acc = 38.862\n",
            "test_acc = 38.97\n",
            "loss = 1.761846496734875\n",
            "\n",
            "epoch :  540 / 700\n",
            "train_acc = 38.873999999999995\n",
            "test_acc = 38.96\n",
            "loss = 1.7616410376091443\n",
            "\n",
            "epoch :  541 / 700\n",
            "train_acc = 38.876\n",
            "test_acc = 38.97\n",
            "loss = 1.7614358937517134\n",
            "\n",
            "epoch :  542 / 700\n",
            "train_acc = 38.876\n",
            "test_acc = 38.97\n",
            "loss = 1.7612310637026267\n",
            "\n",
            "epoch :  543 / 700\n",
            "train_acc = 38.882\n",
            "test_acc = 38.97\n",
            "loss = 1.761026546010213\n",
            "\n",
            "epoch :  544 / 700\n",
            "train_acc = 38.897999999999996\n",
            "test_acc = 38.97\n",
            "loss = 1.7608223392310882\n",
            "\n",
            "epoch :  545 / 700\n",
            "train_acc = 38.908\n",
            "test_acc = 38.98\n",
            "loss = 1.7606184419301514\n",
            "\n",
            "epoch :  546 / 700\n",
            "train_acc = 38.92\n",
            "test_acc = 38.99\n",
            "loss = 1.7604148526805838\n",
            "\n",
            "epoch :  547 / 700\n",
            "train_acc = 38.922000000000004\n",
            "test_acc = 39.0\n",
            "loss = 1.760211570063846\n",
            "\n",
            "epoch :  548 / 700\n",
            "train_acc = 38.934000000000005\n",
            "test_acc = 39.0\n",
            "loss = 1.7600085926696758\n",
            "\n",
            "epoch :  549 / 700\n",
            "train_acc = 38.940000000000005\n",
            "test_acc = 39.019999999999996\n",
            "loss = 1.7598059190960806\n",
            "\n",
            "epoch :  550 / 700\n",
            "train_acc = 38.952\n",
            "test_acc = 39.019999999999996\n",
            "loss = 1.7596035479493342\n",
            "\n",
            "epoch :  551 / 700\n",
            "train_acc = 38.956\n",
            "test_acc = 39.04\n",
            "loss = 1.7594014778439697\n",
            "\n",
            "epoch :  552 / 700\n",
            "train_acc = 38.968\n",
            "test_acc = 39.04\n",
            "loss = 1.759199707402772\n",
            "\n",
            "epoch :  553 / 700\n",
            "train_acc = 38.978\n",
            "test_acc = 39.06\n",
            "loss = 1.758998235256771\n",
            "\n",
            "epoch :  554 / 700\n",
            "train_acc = 38.984\n",
            "test_acc = 39.07\n",
            "loss = 1.7587970600452298\n",
            "\n",
            "epoch :  555 / 700\n",
            "train_acc = 38.986\n",
            "test_acc = 39.07\n",
            "loss = 1.7585961804156365\n",
            "\n",
            "epoch :  556 / 700\n",
            "train_acc = 38.99\n",
            "test_acc = 39.07\n",
            "loss = 1.7583955950236914\n",
            "\n",
            "epoch :  557 / 700\n",
            "train_acc = 39.007999999999996\n",
            "test_acc = 39.07\n",
            "loss = 1.7581953025332966\n",
            "\n",
            "epoch :  558 / 700\n",
            "train_acc = 39.013999999999996\n",
            "test_acc = 39.06\n",
            "loss = 1.7579953016165395\n",
            "\n",
            "epoch :  559 / 700\n",
            "train_acc = 39.025999999999996\n",
            "test_acc = 39.11\n",
            "loss = 1.7577955909536824\n",
            "\n",
            "epoch :  560 / 700\n",
            "train_acc = 39.042\n",
            "test_acc = 39.1\n",
            "loss = 1.757596169233143\n",
            "\n",
            "epoch :  561 / 700\n",
            "train_acc = 39.050000000000004\n",
            "test_acc = 39.1\n",
            "loss = 1.7573970351514812\n",
            "\n",
            "epoch :  562 / 700\n",
            "train_acc = 39.052\n",
            "test_acc = 39.11\n",
            "loss = 1.7571981874133775\n",
            "\n",
            "epoch :  563 / 700\n",
            "train_acc = 39.062000000000005\n",
            "test_acc = 39.1\n",
            "loss = 1.7569996247316193\n",
            "\n",
            "epoch :  564 / 700\n",
            "train_acc = 39.076\n",
            "test_acc = 39.11\n",
            "loss = 1.7568013458270764\n",
            "\n",
            "epoch :  565 / 700\n",
            "train_acc = 39.088\n",
            "test_acc = 39.12\n",
            "loss = 1.7566033494286832\n",
            "\n",
            "epoch :  566 / 700\n",
            "train_acc = 39.094\n",
            "test_acc = 39.12\n",
            "loss = 1.7564056342734145\n",
            "\n",
            "epoch :  567 / 700\n",
            "train_acc = 39.096\n",
            "test_acc = 39.1\n",
            "loss = 1.7562081991062652\n",
            "\n",
            "epoch :  568 / 700\n",
            "train_acc = 39.108\n",
            "test_acc = 39.1\n",
            "loss = 1.7560110426802231\n",
            "\n",
            "epoch :  569 / 700\n",
            "train_acc = 39.112\n",
            "test_acc = 39.12\n",
            "loss = 1.755814163756246\n",
            "\n",
            "epoch :  570 / 700\n",
            "train_acc = 39.128\n",
            "test_acc = 39.129999999999995\n",
            "loss = 1.7556175611032354\n",
            "\n",
            "epoch :  571 / 700\n",
            "train_acc = 39.123999999999995\n",
            "test_acc = 39.14\n",
            "loss = 1.7554212334980068\n",
            "\n",
            "epoch :  572 / 700\n",
            "train_acc = 39.14\n",
            "test_acc = 39.160000000000004\n",
            "loss = 1.7552251797252654\n",
            "\n",
            "epoch :  573 / 700\n",
            "train_acc = 39.144\n",
            "test_acc = 39.160000000000004\n",
            "loss = 1.7550293985775727\n",
            "\n",
            "epoch :  574 / 700\n",
            "train_acc = 39.146\n",
            "test_acc = 39.190000000000005\n",
            "loss = 1.7548338888553199\n",
            "\n",
            "epoch :  575 / 700\n",
            "train_acc = 39.141999999999996\n",
            "test_acc = 39.190000000000005\n",
            "loss = 1.7546386493666941\n",
            "\n",
            "epoch :  576 / 700\n",
            "train_acc = 39.146\n",
            "test_acc = 39.190000000000005\n",
            "loss = 1.7544436789276467\n",
            "\n",
            "epoch :  577 / 700\n",
            "train_acc = 39.158\n",
            "test_acc = 39.190000000000005\n",
            "loss = 1.7542489763618612\n",
            "\n",
            "epoch :  578 / 700\n",
            "train_acc = 39.174\n",
            "test_acc = 39.18\n",
            "loss = 1.7540545405007177\n",
            "\n",
            "epoch :  579 / 700\n",
            "train_acc = 39.184000000000005\n",
            "test_acc = 39.2\n",
            "loss = 1.7538603701832576\n",
            "\n",
            "epoch :  580 / 700\n",
            "train_acc = 39.194\n",
            "test_acc = 39.190000000000005\n",
            "loss = 1.7536664642561506\n",
            "\n",
            "epoch :  581 / 700\n",
            "train_acc = 39.206\n",
            "test_acc = 39.21\n",
            "loss = 1.7534728215736521\n",
            "\n",
            "epoch :  582 / 700\n",
            "train_acc = 39.21\n",
            "test_acc = 39.2\n",
            "loss = 1.7532794409975723\n",
            "\n",
            "epoch :  583 / 700\n",
            "train_acc = 39.222\n",
            "test_acc = 39.21\n",
            "loss = 1.7530863213972319\n",
            "\n",
            "epoch :  584 / 700\n",
            "train_acc = 39.224\n",
            "test_acc = 39.22\n",
            "loss = 1.7528934616494254\n",
            "\n",
            "epoch :  585 / 700\n",
            "train_acc = 39.234\n",
            "test_acc = 39.23\n",
            "loss = 1.7527008606383805\n",
            "\n",
            "epoch :  586 / 700\n",
            "train_acc = 39.248\n",
            "test_acc = 39.24\n",
            "loss = 1.7525085172557175\n",
            "\n",
            "epoch :  587 / 700\n",
            "train_acc = 39.251999999999995\n",
            "test_acc = 39.26\n",
            "loss = 1.7523164304004049\n",
            "\n",
            "epoch :  588 / 700\n",
            "train_acc = 39.254\n",
            "test_acc = 39.28\n",
            "loss = 1.7521245989787202\n",
            "\n",
            "epoch :  589 / 700\n",
            "train_acc = 39.266\n",
            "test_acc = 39.290000000000006\n",
            "loss = 1.751933021904204\n",
            "\n",
            "epoch :  590 / 700\n",
            "train_acc = 39.274\n",
            "test_acc = 39.32\n",
            "loss = 1.7517416980976181\n",
            "\n",
            "epoch :  591 / 700\n",
            "train_acc = 39.274\n",
            "test_acc = 39.33\n",
            "loss = 1.7515506264868983\n",
            "\n",
            "epoch :  592 / 700\n",
            "train_acc = 39.282000000000004\n",
            "test_acc = 39.36\n",
            "loss = 1.7513598060071112\n",
            "\n",
            "epoch :  593 / 700\n",
            "train_acc = 39.28\n",
            "test_acc = 39.36\n",
            "loss = 1.7511692356004065\n",
            "\n",
            "epoch :  594 / 700\n",
            "train_acc = 39.288000000000004\n",
            "test_acc = 39.35\n",
            "loss = 1.7509789142159717\n",
            "\n",
            "epoch :  595 / 700\n",
            "train_acc = 39.294000000000004\n",
            "test_acc = 39.39\n",
            "loss = 1.750788840809984\n",
            "\n",
            "epoch :  596 / 700\n",
            "train_acc = 39.300000000000004\n",
            "test_acc = 39.4\n",
            "loss = 1.7505990143455625\n",
            "\n",
            "epoch :  597 / 700\n",
            "train_acc = 39.302\n",
            "test_acc = 39.39\n",
            "loss = 1.750409433792719\n",
            "\n",
            "epoch :  598 / 700\n",
            "train_acc = 39.312000000000005\n",
            "test_acc = 39.4\n",
            "loss = 1.7502200981283131\n",
            "\n",
            "epoch :  599 / 700\n",
            "train_acc = 39.322\n",
            "test_acc = 39.4\n",
            "loss = 1.7500310063359963\n",
            "\n",
            "epoch :  600 / 700\n",
            "train_acc = 39.328\n",
            "test_acc = 39.410000000000004\n",
            "loss = 1.7498421574061673\n",
            "\n",
            "epoch :  601 / 700\n",
            "train_acc = 39.326\n",
            "test_acc = 39.43\n",
            "loss = 1.749653550335919\n",
            "\n",
            "epoch :  602 / 700\n",
            "train_acc = 39.332\n",
            "test_acc = 39.43\n",
            "loss = 1.7494651841289899\n",
            "\n",
            "epoch :  603 / 700\n",
            "train_acc = 39.342\n",
            "test_acc = 39.44\n",
            "loss = 1.749277057795709\n",
            "\n",
            "epoch :  604 / 700\n",
            "train_acc = 39.35\n",
            "test_acc = 39.45\n",
            "loss = 1.7490891703529492\n",
            "\n",
            "epoch :  605 / 700\n",
            "train_acc = 39.356\n",
            "test_acc = 39.45\n",
            "loss = 1.7489015208240712\n",
            "\n",
            "epoch :  606 / 700\n",
            "train_acc = 39.362\n",
            "test_acc = 39.45\n",
            "loss = 1.7487141082388737\n",
            "\n",
            "epoch :  607 / 700\n",
            "train_acc = 39.36\n",
            "test_acc = 39.48\n",
            "loss = 1.74852693163354\n",
            "\n",
            "epoch :  608 / 700\n",
            "train_acc = 39.372\n",
            "test_acc = 39.5\n",
            "loss = 1.7483399900505838\n",
            "\n",
            "epoch :  609 / 700\n",
            "train_acc = 39.376\n",
            "test_acc = 39.51\n",
            "loss = 1.748153282538798\n",
            "\n",
            "epoch :  610 / 700\n",
            "train_acc = 39.382\n",
            "test_acc = 39.519999999999996\n",
            "loss = 1.7479668081532007\n",
            "\n",
            "epoch :  611 / 700\n",
            "train_acc = 39.385999999999996\n",
            "test_acc = 39.53\n",
            "loss = 1.74778056595498\n",
            "\n",
            "epoch :  612 / 700\n",
            "train_acc = 39.39\n",
            "test_acc = 39.54\n",
            "loss = 1.7475945550114418\n",
            "\n",
            "epoch :  613 / 700\n",
            "train_acc = 39.397999999999996\n",
            "test_acc = 39.53\n",
            "loss = 1.7474087743959557\n",
            "\n",
            "epoch :  614 / 700\n",
            "train_acc = 39.397999999999996\n",
            "test_acc = 39.550000000000004\n",
            "loss = 1.7472232231879004\n",
            "\n",
            "epoch :  615 / 700\n",
            "train_acc = 39.404\n",
            "test_acc = 39.58\n",
            "loss = 1.7470379004726069\n",
            "\n",
            "epoch :  616 / 700\n",
            "train_acc = 39.408\n",
            "test_acc = 39.6\n",
            "loss = 1.746852805341309\n",
            "\n",
            "epoch :  617 / 700\n",
            "train_acc = 39.42\n",
            "test_acc = 39.6\n",
            "loss = 1.746667936891085\n",
            "\n",
            "epoch :  618 / 700\n",
            "train_acc = 39.428000000000004\n",
            "test_acc = 39.61\n",
            "loss = 1.7464832942248023\n",
            "\n",
            "epoch :  619 / 700\n",
            "train_acc = 39.44\n",
            "test_acc = 39.629999999999995\n",
            "loss = 1.7462988764510672\n",
            "\n",
            "epoch :  620 / 700\n",
            "train_acc = 39.45\n",
            "test_acc = 39.660000000000004\n",
            "loss = 1.7461146826841645\n",
            "\n",
            "epoch :  621 / 700\n",
            "train_acc = 39.444\n",
            "test_acc = 39.660000000000004\n",
            "loss = 1.7459307120440064\n",
            "\n",
            "epoch :  622 / 700\n",
            "train_acc = 39.438\n",
            "test_acc = 39.67\n",
            "loss = 1.7457469636560765\n",
            "\n",
            "epoch :  623 / 700\n",
            "train_acc = 39.452\n",
            "test_acc = 39.73\n",
            "loss = 1.7455634366513755\n",
            "\n",
            "epoch :  624 / 700\n",
            "train_acc = 39.454\n",
            "test_acc = 39.739999999999995\n",
            "loss = 1.745380130166366\n",
            "\n",
            "epoch :  625 / 700\n",
            "train_acc = 39.462\n",
            "test_acc = 39.739999999999995\n",
            "loss = 1.7451970433429176\n",
            "\n",
            "epoch :  626 / 700\n",
            "train_acc = 39.472\n",
            "test_acc = 39.75\n",
            "loss = 1.7450141753282522\n",
            "\n",
            "epoch :  627 / 700\n",
            "train_acc = 39.486\n",
            "test_acc = 39.75\n",
            "loss = 1.7448315252748905\n",
            "\n",
            "epoch :  628 / 700\n",
            "train_acc = 39.495999999999995\n",
            "test_acc = 39.75\n",
            "loss = 1.7446490923405973\n",
            "\n",
            "epoch :  629 / 700\n",
            "train_acc = 39.495999999999995\n",
            "test_acc = 39.75\n",
            "loss = 1.7444668756883261\n",
            "\n",
            "epoch :  630 / 700\n",
            "train_acc = 39.501999999999995\n",
            "test_acc = 39.75\n",
            "loss = 1.7442848744861668\n",
            "\n",
            "epoch :  631 / 700\n",
            "train_acc = 39.506\n",
            "test_acc = 39.77\n",
            "loss = 1.7441030879072894\n",
            "\n",
            "epoch :  632 / 700\n",
            "train_acc = 39.512\n",
            "test_acc = 39.77\n",
            "loss = 1.7439215151298926\n",
            "\n",
            "epoch :  633 / 700\n",
            "train_acc = 39.518\n",
            "test_acc = 39.78\n",
            "loss = 1.7437401553371503\n",
            "\n",
            "epoch :  634 / 700\n",
            "train_acc = 39.516\n",
            "test_acc = 39.800000000000004\n",
            "loss = 1.7435590077171557\n",
            "\n",
            "epoch :  635 / 700\n",
            "train_acc = 39.513999999999996\n",
            "test_acc = 39.81\n",
            "loss = 1.7433780714628695\n",
            "\n",
            "epoch :  636 / 700\n",
            "train_acc = 39.524\n",
            "test_acc = 39.839999999999996\n",
            "loss = 1.743197345772069\n",
            "\n",
            "epoch :  637 / 700\n",
            "train_acc = 39.544000000000004\n",
            "test_acc = 39.85\n",
            "loss = 1.7430168298472934\n",
            "\n",
            "epoch :  638 / 700\n",
            "train_acc = 39.546\n",
            "test_acc = 39.86\n",
            "loss = 1.7428365228957916\n",
            "\n",
            "epoch :  639 / 700\n",
            "train_acc = 39.554\n",
            "test_acc = 39.86\n",
            "loss = 1.7426564241294713\n",
            "\n",
            "epoch :  640 / 700\n",
            "train_acc = 39.558\n",
            "test_acc = 39.839999999999996\n",
            "loss = 1.7424765327648453\n",
            "\n",
            "epoch :  641 / 700\n",
            "train_acc = 39.564\n",
            "test_acc = 39.85\n",
            "loss = 1.7422968480229846\n",
            "\n",
            "epoch :  642 / 700\n",
            "train_acc = 39.572\n",
            "test_acc = 39.85\n",
            "loss = 1.742117369129461\n",
            "\n",
            "epoch :  643 / 700\n",
            "train_acc = 39.578\n",
            "test_acc = 39.83\n",
            "loss = 1.7419380953143027\n",
            "\n",
            "epoch :  644 / 700\n",
            "train_acc = 39.594\n",
            "test_acc = 39.85\n",
            "loss = 1.741759025811939\n",
            "\n",
            "epoch :  645 / 700\n",
            "train_acc = 39.594\n",
            "test_acc = 39.839999999999996\n",
            "loss = 1.7415801598611553\n",
            "\n",
            "epoch :  646 / 700\n",
            "train_acc = 39.594\n",
            "test_acc = 39.86\n",
            "loss = 1.7414014967050384\n",
            "\n",
            "epoch :  647 / 700\n",
            "train_acc = 39.606\n",
            "test_acc = 39.89\n",
            "loss = 1.7412230355909322\n",
            "\n",
            "epoch :  648 / 700\n",
            "train_acc = 39.604\n",
            "test_acc = 39.879999999999995\n",
            "loss = 1.741044775770386\n",
            "\n",
            "epoch :  649 / 700\n",
            "train_acc = 39.617999999999995\n",
            "test_acc = 39.879999999999995\n",
            "loss = 1.7408667164991072\n",
            "\n",
            "epoch :  650 / 700\n",
            "train_acc = 39.628\n",
            "test_acc = 39.879999999999995\n",
            "loss = 1.740688857036914\n",
            "\n",
            "epoch :  651 / 700\n",
            "train_acc = 39.635999999999996\n",
            "test_acc = 39.86\n",
            "loss = 1.7405111966476874\n",
            "\n",
            "epoch :  652 / 700\n",
            "train_acc = 39.644\n",
            "test_acc = 39.86\n",
            "loss = 1.7403337345993246\n",
            "\n",
            "epoch :  653 / 700\n",
            "train_acc = 39.64\n",
            "test_acc = 39.879999999999995\n",
            "loss = 1.7401564701636947\n",
            "\n",
            "epoch :  654 / 700\n",
            "train_acc = 39.648\n",
            "test_acc = 39.89\n",
            "loss = 1.7399794026165871\n",
            "\n",
            "epoch :  655 / 700\n",
            "train_acc = 39.654\n",
            "test_acc = 39.89\n",
            "loss = 1.7398025312376735\n",
            "\n",
            "epoch :  656 / 700\n",
            "train_acc = 39.658\n",
            "test_acc = 39.900000000000006\n",
            "loss = 1.7396258553104569\n",
            "\n",
            "epoch :  657 / 700\n",
            "train_acc = 39.664\n",
            "test_acc = 39.910000000000004\n",
            "loss = 1.7394493741222323\n",
            "\n",
            "epoch :  658 / 700\n",
            "train_acc = 39.67\n",
            "test_acc = 39.92\n",
            "loss = 1.7392730869640383\n",
            "\n",
            "epoch :  659 / 700\n",
            "train_acc = 39.684000000000005\n",
            "test_acc = 39.910000000000004\n",
            "loss = 1.7390969931306164\n",
            "\n",
            "epoch :  660 / 700\n",
            "train_acc = 39.688\n",
            "test_acc = 39.92\n",
            "loss = 1.7389210919203686\n",
            "\n",
            "epoch :  661 / 700\n",
            "train_acc = 39.688\n",
            "test_acc = 39.93\n",
            "loss = 1.7387453826353132\n",
            "\n",
            "epoch :  662 / 700\n",
            "train_acc = 39.686\n",
            "test_acc = 39.93\n",
            "loss = 1.7385698645810455\n",
            "\n",
            "epoch :  663 / 700\n",
            "train_acc = 39.696\n",
            "test_acc = 39.95\n",
            "loss = 1.738394537066695\n",
            "\n",
            "epoch :  664 / 700\n",
            "train_acc = 39.708\n",
            "test_acc = 39.95\n",
            "loss = 1.7382193994048851\n",
            "\n",
            "epoch :  665 / 700\n",
            "train_acc = 39.716\n",
            "test_acc = 39.93\n",
            "loss = 1.738044450911693\n",
            "\n",
            "epoch :  666 / 700\n",
            "train_acc = 39.724\n",
            "test_acc = 39.92\n",
            "loss = 1.737869690906612\n",
            "\n",
            "epoch :  667 / 700\n",
            "train_acc = 39.728\n",
            "test_acc = 39.92\n",
            "loss = 1.7376951187125111\n",
            "\n",
            "epoch :  668 / 700\n",
            "train_acc = 39.736\n",
            "test_acc = 39.93\n",
            "loss = 1.7375207336555962\n",
            "\n",
            "epoch :  669 / 700\n",
            "train_acc = 39.744\n",
            "test_acc = 39.92\n",
            "loss = 1.7373465350653747\n",
            "\n",
            "epoch :  670 / 700\n",
            "train_acc = 39.757999999999996\n",
            "test_acc = 39.910000000000004\n",
            "loss = 1.737172522274616\n",
            "\n",
            "epoch :  671 / 700\n",
            "train_acc = 39.763999999999996\n",
            "test_acc = 39.900000000000006\n",
            "loss = 1.7369986946193179\n",
            "\n",
            "epoch :  672 / 700\n",
            "train_acc = 39.776\n",
            "test_acc = 39.93\n",
            "loss = 1.736825051438667\n",
            "\n",
            "epoch :  673 / 700\n",
            "train_acc = 39.784000000000006\n",
            "test_acc = 39.93\n",
            "loss = 1.7366515920750074\n",
            "\n",
            "epoch :  674 / 700\n",
            "train_acc = 39.792\n",
            "test_acc = 39.94\n",
            "loss = 1.736478315873803\n",
            "\n",
            "epoch :  675 / 700\n",
            "train_acc = 39.794000000000004\n",
            "test_acc = 39.96\n",
            "loss = 1.7363052221836062\n",
            "\n",
            "epoch :  676 / 700\n",
            "train_acc = 39.81\n",
            "test_acc = 39.96\n",
            "loss = 1.7361323103560218\n",
            "\n",
            "epoch :  677 / 700\n",
            "train_acc = 39.822\n",
            "test_acc = 39.95\n",
            "loss = 1.7359595797456755\n",
            "\n",
            "epoch :  678 / 700\n",
            "train_acc = 39.83\n",
            "test_acc = 39.96\n",
            "loss = 1.7357870297101834\n",
            "\n",
            "epoch :  679 / 700\n",
            "train_acc = 39.83\n",
            "test_acc = 39.96\n",
            "loss = 1.735614659610116\n",
            "\n",
            "epoch :  680 / 700\n",
            "train_acc = 39.83\n",
            "test_acc = 39.97\n",
            "loss = 1.7354424688089716\n",
            "\n",
            "epoch :  681 / 700\n",
            "train_acc = 39.832\n",
            "test_acc = 39.97\n",
            "loss = 1.7352704566731445\n",
            "\n",
            "epoch :  682 / 700\n",
            "train_acc = 39.838\n",
            "test_acc = 39.96\n",
            "loss = 1.7350986225718943\n",
            "\n",
            "epoch :  683 / 700\n",
            "train_acc = 39.838\n",
            "test_acc = 39.97\n",
            "loss = 1.7349269658773172\n",
            "\n",
            "epoch :  684 / 700\n",
            "train_acc = 39.842\n",
            "test_acc = 39.97\n",
            "loss = 1.7347554859643184\n",
            "\n",
            "epoch :  685 / 700\n",
            "train_acc = 39.856\n",
            "test_acc = 39.989999999999995\n",
            "loss = 1.7345841822105825\n",
            "\n",
            "epoch :  686 / 700\n",
            "train_acc = 39.87\n",
            "test_acc = 39.989999999999995\n",
            "loss = 1.7344130539965492\n",
            "\n",
            "epoch :  687 / 700\n",
            "train_acc = 39.876\n",
            "test_acc = 39.989999999999995\n",
            "loss = 1.734242100705382\n",
            "\n",
            "epoch :  688 / 700\n",
            "train_acc = 39.89\n",
            "test_acc = 39.98\n",
            "loss = 1.7340713217229464\n",
            "\n",
            "epoch :  689 / 700\n",
            "train_acc = 39.882\n",
            "test_acc = 40.01\n",
            "loss = 1.733900716437781\n",
            "\n",
            "epoch :  690 / 700\n",
            "train_acc = 39.885999999999996\n",
            "test_acc = 40.0\n",
            "loss = 1.7337302842410753\n",
            "\n",
            "epoch :  691 / 700\n",
            "train_acc = 39.89\n",
            "test_acc = 40.01\n",
            "loss = 1.7335600245266438\n",
            "\n",
            "epoch :  692 / 700\n",
            "train_acc = 39.896\n",
            "test_acc = 40.02\n",
            "loss = 1.7333899366909022\n",
            "\n",
            "epoch :  693 / 700\n",
            "train_acc = 39.898\n",
            "test_acc = 40.02\n",
            "loss = 1.733220020132844\n",
            "\n",
            "epoch :  694 / 700\n",
            "train_acc = 39.902\n",
            "test_acc = 40.04\n",
            "loss = 1.7330502742540195\n",
            "\n",
            "epoch :  695 / 700\n",
            "train_acc = 39.910000000000004\n",
            "test_acc = 40.02\n",
            "loss = 1.7328806984585106\n",
            "\n",
            "epoch :  696 / 700\n",
            "train_acc = 39.914\n",
            "test_acc = 40.02\n",
            "loss = 1.7327112921529133\n",
            "\n",
            "epoch :  697 / 700\n",
            "train_acc = 39.924\n",
            "test_acc = 40.01\n",
            "loss = 1.7325420547463133\n",
            "\n",
            "epoch :  698 / 700\n",
            "train_acc = 39.928000000000004\n",
            "test_acc = 40.0\n",
            "loss = 1.7323729856502679\n",
            "\n",
            "epoch :  699 / 700\n",
            "train_acc = 39.932\n",
            "test_acc = 40.0\n",
            "loss = 1.7322040842787838\n",
            "\n",
            "epoch :  700 / 700\n",
            "train_acc = 39.936\n",
            "test_acc = 40.0\n",
            "loss = 1.7320353500483001\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uEZBmVJy4qFe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "outputId": "4364252c-757b-4c35-9d55-f03d5a8225cd"
      },
      "source": [
        "# Step 7: Evaluation of SLA by tuning Tune-Hyperparameters\n",
        "\n",
        "#loss Plot\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.plot(losstrack_train,color='blue',label='Training Loss')\n",
        "plt.plot(losstrack_test,color='orange', label='Testing Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "#Accuracy Plot\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.plot(train_accuracy,color='blue',label='Training Accuracy')\n",
        "plt.plot(test_accuracy,color='orange', label='Testing Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jBu_mx_Q4s7i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bea4b36d-4286-4d70-8a65-b959277a068b"
      },
      "source": [
        "#Confusion Matrix\n",
        "Z1_test = np.dot(W1,x_test) + b1\n",
        "A1_test = sigmoid(Z1_test)\n",
        "Z2_test = np.dot(W2,A1_test) + b2\n",
        "A2_test = softmax(Z2_test)\n",
        "\n",
        "y_test  = np.argmax(y_test,axis=0)\n",
        "A2_test = np.argmax(A2_test,axis=0)\n",
        "\n",
        "cm = confusion_matrix(y_test, A2_test)\n",
        "print(cm)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[469  40  61  17  15  18  29  52 227  72]\n",
            " [ 64 455  25  46  20  36  48  40  93 173]\n",
            " [126  47 261  73 124  87 140  65  51  26]\n",
            " [ 51  77  80 259  48 207 120  64  33  61]\n",
            " [ 74  33 148  63 301  72 160  96  30  23]\n",
            " [ 44  34  97 163  66 324 120  79  49  24]\n",
            " [ 16  51  80  93  92  78 497  35  16  42]\n",
            " [ 49  56  74  74  98  64  68 394  42  81]\n",
            " [138  78  15  26   6  43   9  25 566  94]\n",
            " [ 60 162  11  38  14  25  49  48 117 476]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ikXVQ4G65m6b"
      },
      "source": [
        "# End Of SLA"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KKMRjK2u433E"
      },
      "source": [
        "### UNSUPERVISED LEARNING APPROACH (USLA) ###"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pyr_cwa05sXy"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzZMVpuJBZ1k"
      },
      "source": [
        "# Scaling Features\n",
        "\n",
        "x_train = x_train / 255\n",
        "x_test = x_test / 255"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XfiFbeP3Be_H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "331e22cf-9ddf-4554-b50c-7bb264569397"
      },
      "source": [
        "# Step 8: Convolutional AutoEncoder\n",
        "\n",
        "input_img = tf.keras.Input(shape=(32, 32, 3))\n",
        " \n",
        "x = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', padding='same')(input_img)\n",
        "x = tf.keras.layers.MaxPooling2D((2, 2), padding='same')(x)\n",
        "x = tf.keras.layers.Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
        "x = tf.keras.layers.MaxPooling2D((2, 2), padding='same')(x)\n",
        "x = tf.keras.layers.Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
        "encoded = tf.keras.layers.MaxPooling2D((2, 2), padding='same')(x)\n",
        "\n",
        "x = tf.keras.layers.Conv2D(8, (3, 3), activation='relu', padding='same')(encoded)\n",
        "x = tf.keras.layers.UpSampling2D((2, 2))(x)\n",
        "x = tf.keras.layers.Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
        "x = tf.keras.layers.UpSampling2D((2, 2))(x)\n",
        "x = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n",
        "x = tf.keras.layers.UpSampling2D((2, 2))(x)\n",
        "decoded = tf.keras.layers.Conv2D(3, (3, 3), activation='sigmoid', padding='same')(x)\n",
        "\n",
        "autoencoder = tf.keras.Model(input_img, decoded)\n",
        "optim = tf.keras.optimizers.SGD(learning_rate=0.3, name='SGD')\n",
        "autoencoder.summary()\n",
        "autoencoder.compile(optimizer=optim, loss='mse')\n",
        "autoencoder.fit(x_train, x_train,epochs=25,batch_size=128,shuffle=True,validation_data=(x_test, x_test))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 32, 32, 16)        448       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 16, 16, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 16, 16, 8)         1160      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 8, 8, 8)           0         \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 8, 8, 8)           584       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 4, 4, 8)           0         \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 4, 4, 8)           584       \n",
            "_________________________________________________________________\n",
            "up_sampling2d_3 (UpSampling2 (None, 8, 8, 8)           0         \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 8, 8, 8)           584       \n",
            "_________________________________________________________________\n",
            "up_sampling2d_4 (UpSampling2 (None, 16, 16, 8)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_12 (Conv2D)           (None, 16, 16, 16)        1168      \n",
            "_________________________________________________________________\n",
            "up_sampling2d_5 (UpSampling2 (None, 32, 32, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 32, 32, 3)         435       \n",
            "=================================================================\n",
            "Total params: 4,963\n",
            "Trainable params: 4,963\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "391/391 [==============================] - 98s 250ms/step - loss: 0.0479 - val_loss: 0.0335\n",
            "Epoch 2/25\n",
            "391/391 [==============================] - 97s 248ms/step - loss: 0.0318 - val_loss: 0.0305\n",
            "Epoch 3/25\n",
            "391/391 [==============================] - 98s 250ms/step - loss: 0.0293 - val_loss: 0.0270\n",
            "Epoch 4/25\n",
            "391/391 [==============================] - 97s 248ms/step - loss: 0.0279 - val_loss: 0.0301\n",
            "Epoch 5/25\n",
            "391/391 [==============================] - 100s 256ms/step - loss: 0.0268 - val_loss: 0.0247\n",
            "Epoch 6/25\n",
            "391/391 [==============================] - 97s 249ms/step - loss: 0.0254 - val_loss: 0.0255\n",
            "Epoch 7/25\n",
            "391/391 [==============================] - 98s 250ms/step - loss: 0.0243 - val_loss: 0.0242\n",
            "Epoch 8/25\n",
            "391/391 [==============================] - 98s 252ms/step - loss: 0.0234 - val_loss: 0.0226\n",
            "Epoch 9/25\n",
            "391/391 [==============================] - 97s 248ms/step - loss: 0.0228 - val_loss: 0.0228\n",
            "Epoch 10/25\n",
            "391/391 [==============================] - 98s 249ms/step - loss: 0.0222 - val_loss: 0.0217\n",
            "Epoch 11/25\n",
            "391/391 [==============================] - 98s 250ms/step - loss: 0.0217 - val_loss: 0.0225\n",
            "Epoch 12/25\n",
            "391/391 [==============================] - 97s 248ms/step - loss: 0.0213 - val_loss: 0.0203\n",
            "Epoch 13/25\n",
            "391/391 [==============================] - 97s 249ms/step - loss: 0.0209 - val_loss: 0.0222\n",
            "Epoch 14/25\n",
            "391/391 [==============================] - 99s 252ms/step - loss: 0.0207 - val_loss: 0.0214\n",
            "Epoch 15/25\n",
            "391/391 [==============================] - 97s 249ms/step - loss: 0.0203 - val_loss: 0.0200\n",
            "Epoch 16/25\n",
            "391/391 [==============================] - 98s 251ms/step - loss: 0.0200 - val_loss: 0.0193\n",
            "Epoch 17/25\n",
            "391/391 [==============================] - 98s 250ms/step - loss: 0.0198 - val_loss: 0.0212\n",
            "Epoch 18/25\n",
            "391/391 [==============================] - 99s 253ms/step - loss: 0.0196 - val_loss: 0.0197\n",
            "Epoch 19/25\n",
            "391/391 [==============================] - 97s 249ms/step - loss: 0.0195 - val_loss: 0.0202\n",
            "Epoch 20/25\n",
            "391/391 [==============================] - 97s 247ms/step - loss: 0.0193 - val_loss: 0.0191\n",
            "Epoch 21/25\n",
            "391/391 [==============================] - 97s 249ms/step - loss: 0.0192 - val_loss: 0.0186\n",
            "Epoch 22/25\n",
            "391/391 [==============================] - 97s 248ms/step - loss: 0.0190 - val_loss: 0.0184\n",
            "Epoch 23/25\n",
            "391/391 [==============================] - 97s 248ms/step - loss: 0.0189 - val_loss: 0.0211\n",
            "Epoch 24/25\n",
            "391/391 [==============================] - 97s 249ms/step - loss: 0.0188 - val_loss: 0.0180\n",
            "Epoch 25/25\n",
            "391/391 [==============================] - 97s 248ms/step - loss: 0.0183 - val_loss: 0.0172\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f562f524cc0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_RBmXg_BCT0Z"
      },
      "source": [
        "# Fetch the image features for entire dataset from latent layer of auto-encoder\n",
        "\n",
        "encoder=keras.Model(input_img,encoded)\n",
        "\n",
        "encoded_imgs=encoder.predict(x_train)\n",
        "encoded_imgs=encoded_imgs.reshape(x_train.shape[0],128)\n",
        "\n",
        "encoded_imgs_test=encoder.predict(x_test)\n",
        "encoded_imgs_test=encoded_imgs_test.reshape(x_test.shape[0],128)\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qffbEu67DiLL"
      },
      "source": [
        "# Step 9: Kmeans clustering\n",
        "\n",
        "kmeans=KMeans(n_clusters=10)\n",
        "encoded_imgs_fit=kmeans.fit(encoded_imgs)\n",
        "\n",
        "kmeans_test=KMeans(n_clusters=10)\n",
        "encoded_imgs_fit_test=kmeans_test.fit(encoded_imgs_test)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8NwvD1wDt9Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "050a50b9-62c1-48c7-eae8-cdf60d20dee0"
      },
      "source": [
        "# Step 10: Evalutation USLA\n",
        "\n",
        "#finding train_accuracy\n",
        "labels=encoded_imgs_fit.labels_\n",
        "\n",
        "confusionmatrix=confusion_matrix(labels,y_train)\n",
        "\n",
        "index = linear_assignment(-confusionmatrix)\n",
        "index = list(index)\n",
        "index[1] = list(index[1])\n",
        "true_clusters=index[1]\n",
        "print(\"True cluster label order:\",true_clusters)\n",
        "labelmap=[]\n",
        "for i in range(10):\n",
        "    labelmap.append(confusionmatrix[i][true_clusters[i]])\n",
        "\n",
        "n = np.sum(confusionmatrix)\n",
        "train_accuracy = np.sum(labelmap) / n * 100\n",
        "print(train_accuracy)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True cluster label order: [3, 0, 9, 5, 4, 7, 6, 8, 2, 1]\n",
            "21.086\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VX6uNKcgd_9g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7771740f-4726-4415-f601-645d55982e3e"
      },
      "source": [
        " #finding train_accuracy\n",
        "labels_test=encoded_imgs_fit_test.labels_\n",
        "\n",
        "confusionmatrix_test=confusion_matrix(labels_test,y_test)\n",
        "\n",
        "index = linear_assignment(-confusionmatrix_test)\n",
        "index = list(index)\n",
        "index[1] = list(index[1])\n",
        "true_clusters=index[1]\n",
        "print(\"True cluster label order:\",true_clusters)\n",
        "labelmap=[]\n",
        "for i in range(10):\n",
        "    labelmap.append(confusionmatrix_test[i][true_clusters[i]])\n",
        "\n",
        "n = np.sum(confusionmatrix_test)\n",
        "test_accuracy = np.sum(labelmap) / n * 100\n",
        "print(test_accuracy)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True cluster label order: [5, 3, 1, 7, 8, 2, 0, 9, 4, 6]\n",
            "20.77\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rZHi6gWyEKYD",
        "outputId": "3861c532-8d63-4b7f-bbb4-3245e7dbb0b2"
      },
      "source": [
        "#confusion Matrix for test data\n",
        "for i in range(x_test.shape[0]):\n",
        "    labels_test[i]=true_clusters[labels_test[i]]\n",
        "\n",
        "confusionmatrix_test_data=confusion_matrix(labels_test,y_test)\n",
        "\n",
        "print(confusionmatrix_test_data)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[213  71  77  64  12  41  58  44  35  65]\n",
            " [ 30 122 103 124  87  81 138  54  29  41]\n",
            " [187  31 112  74  62 112  28  58 120  37]\n",
            " [ 41  47  56 142 114 153  58 132  44  27]\n",
            " [ 98  99 232 141 211 147 179 140  68  75]\n",
            " [ 46 159  42 103  22 200  48  92 105  59]\n",
            " [ 69  97 240 156 370 105 381 109  37  57]\n",
            " [ 81  73  57  93  40  81  70 112  28 106]\n",
            " [123 110  35  21  26  19   7  69 279 228]\n",
            " [112 191  46  82  56  61  33 190 255 305]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}